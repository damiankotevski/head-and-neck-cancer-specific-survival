{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cb50598",
   "metadata": {},
   "source": [
    "# MULTISITE MACHINE LEARNING ANALYSIS - DAMIAN KOTEVSKI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65c4192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library requirements\n",
    "import pandas as pd, numpy as np\n",
    "from numpy import isnan\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, brier_score_loss\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold, train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import pickle\n",
    "import lifelines\n",
    "from lifelines.utils import concordance_index\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test, multivariate_logrank_test\n",
    "from lifelines.plotting import add_at_risk_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78fd6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "hnc_df = pd.read_csv(\"/PATH/TO/FILE.csv\")\n",
    "hpc_df = pd.read_csv(\"/PATH/TO/FILE.csv\")\n",
    "lyx_df = pd.read_csv(\"/PATH/TO/FILE.csv\")\n",
    "npc_df = pd.read_csv(\"/PATH/TO/FILE.csv\")\n",
    "occ_df = pd.read_csv(\"/PATH/TO/FILE.csv\")\n",
    "opc_df = pd.read_csv(\"/PATH/TO/FILE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2845d7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define imputer\n",
    "imputer = IterativeImputer(estimator=BayesianRidge(),\n",
    "                           n_nearest_features=None, \n",
    "                           imputation_order='ascending', # uses features with fewest missing values first\n",
    "                           initial_strategy='most_frequent') # used for categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddc02c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the imputer on the dataset\n",
    "imputer.fit(hnc_df)\n",
    "imputer.fit(hpc_df)\n",
    "imputer.fit(lyx_df)\n",
    "imputer.fit(npc_df)\n",
    "imputer.fit(occ_df)\n",
    "imputer.fit(opc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142b9cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the dataset\n",
    "transformed_hnc_df = imputer.transform(hnc_df)\n",
    "transformed_hpc_df = imputer.transform(hpc_df)\n",
    "transformed_lyx_df = imputer.transform(lyx_df)\n",
    "transformed_npc_df = imputer.transform(npc_df)\n",
    "transformed_occ_df = imputer.transform(occ_df)\n",
    "transformed_opc_df = imputer.transform(opc_df)\n",
    "\n",
    "# print total missing\n",
    "# print('Missing: %d' % sum(isnan(transformed_hnc_df).flatten()))\n",
    "# print('Missing: %d' % sum(isnan(transformed_hpc_df).flatten()))\n",
    "# print('Missing: %d' % sum(isnan(transformed_lyx_df).flatten()))\n",
    "# print('Missing: %d' % sum(isnan(transformed_npc_df).flatten()))\n",
    "# print('Missing: %d' % sum(isnan(transformed_occ_df).flatten()))\n",
    "# print('Missing: %d' % sum(isnan(transformed_opc_df).flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b089d460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create complete dataframe with imputed data\n",
    "complete_hnc_df = pd.DataFrame(imputer.transform(hnc_df))\n",
    "complete_hpc_df = pd.DataFrame(imputer.transform(hpc_df))\n",
    "complete_lyx_df = pd.DataFrame(imputer.transform(lyx_df))\n",
    "complete_npc_df = pd.DataFrame(imputer.transform(npc_df))\n",
    "complete_occ_df = pd.DataFrame(imputer.transform(occ_df))\n",
    "complete_opc_df = pd.DataFrame(imputer.transform(opc_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a086f799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define columns for dataframe with imputed data\n",
    "complete_hnc_df.columns = ['PatientID', 'Hospital', 'Age', 'Gender', 'TumourSite', 'Tclassification',\n",
    "                       'Nclassification', 'EQD2T', 'SurvivalMonths', 'TwoYearHNCDeath']\n",
    "complete_hpc_df.columns = ['PatientID', 'Hospital', 'Age', 'Gender', 'TumourSite', 'Tclassification',\n",
    "                       'Nclassification', 'EQD2T', 'SurvivalMonths', 'TwoYearHNCDeath']\n",
    "complete_lyx_df.columns = ['PatientID', 'Hospital', 'Age', 'Gender', 'TumourSite', 'Tclassification',\n",
    "                       'Nclassification', 'EQD2T', 'SurvivalMonths', 'TwoYearHNCDeath']\n",
    "complete_npc_df.columns = ['PatientID', 'Hospital', 'Age', 'Gender', 'TumourSite', 'Tclassification',\n",
    "                       'Nclassification', 'EQD2T', 'SurvivalMonths', 'TwoYearHNCDeath']\n",
    "complete_occ_df.columns = ['PatientID', 'Hospital', 'Age', 'Gender', 'TumourSite', 'Tclassification',\n",
    "                       'Nclassification', 'EQD2T', 'SurvivalMonths', 'TwoYearHNCDeath']\n",
    "complete_opc_df.columns = ['PatientID', 'Hospital', 'Age', 'Gender', 'TumourSite', 'Tclassification',\n",
    "                       'Nclassification', 'EQD2T', 'SurvivalMonths', 'TwoYearHNCDeath']\n",
    "\n",
    "# print dataframe with imputed data\n",
    "# print(complete_hnc_df)\n",
    "# print(complete_hpc_df)\n",
    "# print(complete_lyx_df)\n",
    "# print(complete_npc_df)\n",
    "# print(complete_occ_df)\n",
    "# print(complete_opc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec51a68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# round data in imputed dataframe\n",
    "completed_hnc_df = complete_hnc_df.abs().round()\n",
    "completed_hpc_df = complete_hpc_df.abs().round()\n",
    "completed_lyx_df = complete_lyx_df.abs().round()\n",
    "completed_npc_df = complete_npc_df.abs().round()\n",
    "completed_occ_df = complete_occ_df.abs().round()\n",
    "completed_opc_df = complete_opc_df.abs().round()\n",
    "\n",
    "# print rounded dataframe\n",
    "# print(completed_hnc_df)\n",
    "# print(completed_hpc_df)\n",
    "# print(completed_lyx_df)\n",
    "# print(completed_npc_df)\n",
    "# print(completed_occ_df)\n",
    "# print(completed_opc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80702ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the modeling pipeline to evaluate imputation\n",
    "model = RandomForestClassifier()\n",
    "imputer = IterativeImputer()\n",
    "pipeline = Pipeline(steps=[('i', imputer), ('m', model)])\n",
    "\n",
    "# split into input and output elements\n",
    "hnc_data = hnc_df.values\n",
    "ix = [i for i in range(hnc_data.shape[1])]\n",
    "X_hnc, y_hnc = hnc_data[:, ix], hnc_data[:, 4] # based on 'Age' column\n",
    "\n",
    "hpc_data = hpc_df.values\n",
    "ix = [i for i in range(hpc_data.shape[1])]\n",
    "X_hpc, y_hpc = hpc_data[:, ix], hpc_data[:, 4] # based on 'Age' column\n",
    "\n",
    "lyx_data = lyx_df.values\n",
    "ix = [i for i in range(lyx_data.shape[1])]\n",
    "X_lyx, y_lyx = lyx_data[:, ix], lyx_data[:, 4] # based on 'Age' column\n",
    "\n",
    "npc_data = npc_df.values\n",
    "ix = [i for i in range(npc_data.shape[1])]\n",
    "X_npc, y_npc = npc_data[:, ix], npc_data[:, 4] # based on 'Age' column\n",
    "\n",
    "occ_data = occ_df.values\n",
    "ix = [i for i in range(occ_data.shape[1])]\n",
    "X_occ, y_occ = occ_data[:, ix], occ_data[:, 4] # based on 'Age' column\n",
    "\n",
    "opc_data = opc_df.values\n",
    "ix = [i for i in range(opc_data.shape[1])]\n",
    "X_opc, y_opc = opc_data[:, ix], opc_data[:, 4] # based on 'Age' column\n",
    "\n",
    "# define model evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=2, random_state=1)\n",
    "\n",
    "# evaluate model\n",
    "hnc_scores = cross_val_score(pipeline, X_hnc, y_hnc, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# print('Mean Accuracy: %.3f (%.3f)'% (hnc_scores.mean(), hnc_scores.std()))\n",
    "\n",
    "hpc_scores = cross_val_score(pipeline, X_hpc, y_hpc, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# print('Mean Accuracy: %.3f (%.3f)'% (hpc_scores.mean(), hpc_scores.std()))\n",
    "\n",
    "lyx_scores = cross_val_score(pipeline, X_lyx, y_lyx, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# print('Mean Accuracy: %.3f (%.3f)'% (lyx_scores.mean(), lyx_scores.std()))\n",
    "\n",
    "npc_scores = cross_val_score(pipeline, X_npc, y_npc, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# print('Mean Accuracy: %.3f (%.3f)'% (npc_scores.mean(), npc_scores.std()))\n",
    "\n",
    "occ_scores = cross_val_score(pipeline, X_occ, y_occ, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# print('Mean Accuracy: %.3f (%.3f)'% (occ_scores.mean(), occ_scores.std()))\n",
    "\n",
    "opc_scores = cross_val_score(pipeline, X_opc, y_opc, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# print('Mean Accuracy: %.3f (%.3f)'% (opc_scores.mean(), opc_scores.std()))\n",
    "\n",
    "# test imputation\n",
    "# TwoYearHNCDeath_occ_unrounded = complete_occ_df['TwoYearHNCDeath'].value_counts()\n",
    "# print(\"Frequency of TwoYearHNCDeath\")\n",
    "# print(TwoYearHNCDeath_occ_unrounded)\n",
    "# TwoYearHNCDeath_occ_rounded = completed_hnc_df['TwoYearHNCDeath'].value_counts()\n",
    "# print(\"Frequency of TwoYearHNCDeath\")\n",
    "# print(TwoYearHNCDeath_occ_rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743c1efd",
   "metadata": {},
   "source": [
    "# oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be1032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into input and output features\n",
    "X_hnc = completed_hnc_df.drop(axis=1, columns=['PatientID', 'SurvivalMonths', 'TwoYearHNCDeath'])\n",
    "y_hnc = completed_hnc_df['TwoYearHNCDeath']\n",
    "\n",
    "X_hpc = completed_hpc_df.drop(axis=1, columns=['PatientID', 'TumourSite', 'SurvivalMonths', 'TwoYearHNCDeath'])\n",
    "y_hpc = completed_hpc_df['TwoYearHNCDeath']\n",
    "\n",
    "X_lyx = completed_lyx_df.drop(axis=1, columns=['PatientID', 'TumourSite', 'SurvivalMonths', 'TwoYearHNCDeath'])\n",
    "y_lyx = completed_lyx_df['TwoYearHNCDeath']\n",
    "\n",
    "X_npc = completed_npc_df.drop(axis=1, columns=['PatientID', 'TumourSite', 'SurvivalMonths', 'TwoYearHNCDeath'])\n",
    "y_npc = completed_npc_df['TwoYearHNCDeath']\n",
    "\n",
    "X_occ = completed_occ_df.drop(axis=1, columns=['PatientID', 'TumourSite', 'SurvivalMonths', 'TwoYearHNCDeath'])\n",
    "y_occ = completed_occ_df['TwoYearHNCDeath']\n",
    "\n",
    "X_opc = completed_opc_df.drop(axis=1, columns=['PatientID', 'TumourSite', 'SurvivalMonths', 'TwoYearHNCDeath'])\n",
    "y_opc = completed_opc_df['TwoYearHNCDeath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabab92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create balanced dataset\n",
    "smote = SMOTE(random_state=1, k_neighbors=3) \n",
    "X_hnc_smote, y_hnc_smote = smote.fit_resample(X_hnc, y_hnc)\n",
    "X_hpc_smote, y_hpc_smote = smote.fit_resample(X_hpc, y_hpc)\n",
    "X_lyx_smote, y_lyx_smote = smote.fit_resample(X_lyx, y_lyx)\n",
    "X_npc_smote, y_npc_smote = smote.fit_resample(X_npc, y_npc)\n",
    "X_occ_smote, y_occ_smote = smote.fit_resample(X_occ, y_occ)\n",
    "X_opc_smote, y_opc_smote = smote.fit_resample(X_opc, y_opc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57b3155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dataset is balanced\n",
    "# print(f'''Shape of X before SMOTE: {X_hnc.shape}\n",
    "# Shape of X after SMOTE: {X_hnc_smote.shape}''')\n",
    "# print(f'''Shape of y before SMOTE: {y_hnc.shape}\n",
    "# Shape of y after SMOTE: {y_hnc_smote.shape}''')\n",
    "# print('\\nBalance of positive and negative classes (%):')\n",
    "# y_hnc_smote.value_counts(normalize=True) * 100\n",
    "\n",
    "# print(f'''Shape of X before SMOTE: {X_hpc.shape}\n",
    "# Shape of X after SMOTE: {X_hpc_smote.shape}''')\n",
    "# print(f'''Shape of y before SMOTE: {y_hpc.shape}\n",
    "# Shape of y after SMOTE: {y_hpc_smote.shape}''')\n",
    "# print('\\nBalance of positive and negative classes (%):')\n",
    "# y_hpc_smote.value_counts(normalize=True) * 100\n",
    "\n",
    "# print(f'''Shape of X before SMOTE: {X_lyx.shape}\n",
    "# Shape of X after SMOTE: {X_lyx_smote.shape}''')\n",
    "# print(f'''Shape of y before SMOTE: {y_lyx.shape}\n",
    "# Shape of y after SMOTE: {y_lyx_smote.shape}''')\n",
    "# print('\\nBalance of positive and negative classes (%):')\n",
    "# y_lyx_smote.value_counts(normalize=True) * 100\n",
    "\n",
    "# print(f'''Shape of X before SMOTE: {X_npc.shape}\n",
    "# Shape of X after SMOTE: {X_npc_smote.shape}''')\n",
    "# print(f'''Shape of y before SMOTE: {y_npc.shape}\n",
    "# Shape of y after SMOTE: {y_npc_smote.shape}''')\n",
    "# print('\\nBalance of positive and negative classes (%):')\n",
    "# y_npc_smote.value_counts(normalize=True) * 100\n",
    "\n",
    "# print(f'''Shape of X before SMOTE: {X_occ.shape}\n",
    "# Shape of X after SMOTE: {X_occ_smote.shape}''')\n",
    "# print(f'''Shape of y before SMOTE: {y_occ.shape}\n",
    "# Shape of y after SMOTE: {y_occ_smote.shape}''')\n",
    "# print('\\nBalance of positive and negative classes (%):')\n",
    "# y_occ_smote.value_counts(normalize=True) * 100\n",
    "\n",
    "# print(f'''Shape of X before SMOTE: {X_opc.shape}\n",
    "# Shape of X after SMOTE: {X_opc_smote.shape}''')\n",
    "# print(f'''Shape of y before SMOTE: {y_opc.shape}\n",
    "# Shape of y after SMOTE: {y_opc_smote.shape}''')\n",
    "# print('\\nBalance of positive and negative classes (%):')\n",
    "# y_opc_smote.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b48efc",
   "metadata": {},
   "source": [
    "# prediction - hnc dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258cb4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate random forest model\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "# split into 80% train and 20% test using oversampled dataset\n",
    "X_hnc_train, X_hnc_test, y_hnc_train, y_hnc_test = train_test_split(X_hnc_smote, y_hnc_smote, stratify=y_hnc_smote, random_state=0, test_size = 0.2)\n",
    "# use gridsearchCV for parameter tuning \n",
    "max_features = [\"sqrt\", \"log2\"]\n",
    "n_estimators = [10000, 100000]\n",
    "class_weight = [{0:.1, 1:.9}, {0:.2, 1:0.8}, {0:.3, 1:.7}, {0:.4, 1:.6}, {0:.5, 1:.5}]\n",
    "# create parameter dictionary for tuning\n",
    "hnc_rf_param_grid = dict(max_features=max_features,\n",
    "                            n_estimators=n_estimators, \n",
    "                            class_weight=class_weight)\n",
    "# define the gridsearchCV object with 5 CV\n",
    "hnc_grid_search_rf = GridSearchCV(rf, param_grid=hnc_rf_param_grid, cv=5, n_jobs=-1, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4abd92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit the tree gridsearchCV object\n",
    "hnc_grid_search_rf.fit(X_hnc_train, y_hnc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9cd5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best parameters and average accuracy score\n",
    "print(\"Best parameters: {}\".format(hnc_grid_search_rf.best_params_))\n",
    "print(\"Best cross-validation average accuracy score: {:.2f}\".format(hnc_grid_search_rf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2f0de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict outcome on train set\n",
    "y_pred_hnc_rf_grid_search_train = hnc_grid_search_rf.predict(X_hnc_train)\n",
    "# predict probabilities on train set\n",
    "y_prob_hnc_rf_grid_search_train = hnc_grid_search_rf.predict_proba(X_hnc_train)\n",
    "# predict outcome on test set\n",
    "y_pred_hnc_rf_grid_search_test = hnc_grid_search_rf.predict(X_hnc_test)\n",
    "# predict probabilities on test set\n",
    "y_prob_hnc_rf_grid_search_test = hnc_grid_search_rf.predict_proba(X_hnc_test)\n",
    "# print(y_prob_hnc_rf_grid_search_test[:,1])\n",
    "\n",
    "# print the accuracy scores\n",
    "print(\"Accuracy on training set: {:.2f}\".format(accuracy_score(y_hnc_train, y_pred_hnc_rf_grid_search_train)))\n",
    "print(\"Accuracy on test set: {:.2f}\".format(accuracy_score(y_hnc_test, y_pred_hnc_rf_grid_search_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ddaa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance metrics of the tuned model, construct the confusion matrix\n",
    "cm_hnc_rf = confusion_matrix(y_true = y_hnc_test, y_pred = y_pred_hnc_rf_grid_search_test)\n",
    "# plot confusion matrix\n",
    "print(\"Confusion matrix plot of the rf:\")\n",
    "print(cm_hnc_rf)\n",
    "print()\n",
    "print(\"Confusion matrix plot of the rf:\")\n",
    "disease_labels = ['HNC death Absent', 'HNC death Present']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm_hnc_rf)\n",
    "plt.title('Confusion matrix of the rf:')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + disease_labels)\n",
    "ax.set_yticklabels([''] + disease_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2da703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print classification report\n",
    "print(\"Precision, Recall, F1-score for class 0 (HNC death Absent) and class 1 (HNC death Present) classes of the test set:\")\n",
    "print(\"Using random forest model\")\n",
    "print()\n",
    "print(classification_report(y_hnc_test, y_pred_hnc_rf_grid_search_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d569f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create auc roc curve\n",
    "y_pred_proba_hnc_rf = hnc_grid_search_rf.predict_proba(X_hnc_test)[:,1]\n",
    "print(\"Area under curve for random forest:\")\n",
    "print(metrics.roc_auc_score(y_true = y_hnc_test, y_score = y_pred_proba_hnc_rf))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_hnc_test, y_pred_proba_hnc_rf)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='red', lw=2, label='ROC curve random forest')\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc8158a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate c-index\n",
    "# convert pred/proba arrays to dataframes and add column labels\n",
    "X_hnc_test_pred_df = pd.DataFrame([y_pred_hnc_rf_grid_search_test]).transpose()\n",
    "X_hnc_test_pred_df.columns = ['PredictedOutcome']\n",
    "X_hnc_test_proba_df = pd.DataFrame([y_prob_hnc_rf_grid_search_test[:,1]]).transpose()\n",
    "X_hnc_test_proba_df.columns = ['PredictedProbability']\n",
    "\n",
    "# split dataset to include survival time in X for c-index calculation\n",
    "X_hnc_cindex = completed_hnc_df.drop(axis=1, columns=['PatientID', 'TwoYearHNCDeath'])\n",
    "y_hnc_cindex = completed_hnc_df['TwoYearHNCDeath']\n",
    "# create balanced dataset with survival time\n",
    "smote = SMOTE(random_state=1, k_neighbors=5)\n",
    "X_hnc_cindex_smote, y_hnc_cindex_smote = smote.fit_resample(X_hnc_cindex, y_hnc_cindex)\n",
    "# split the dataset into X and y\n",
    "X_hnc_train_cindex, X_hnc_test_cindex, y_hnc_train_cindex, y_hnc_test_cindex = train_test_split(X_hnc_cindex_smote, y_hnc_cindex_smote, stratify=y_hnc_cindex_smote, random_state=0, test_size = 0.2)\n",
    "\n",
    "# append predicted outcome and probability to test set using indexes\n",
    "hnc_X_test_df = X_hnc_test.copy()\n",
    "hnc_X_test_df['SurvivalMonths'] = X_hnc_test_cindex['SurvivalMonths']\n",
    "hnc_X_test_df['TwoYearHNCDeath']= y_hnc_test\n",
    "hnc_X_test_df.reset_index(inplace=True)\n",
    "hnc_X_test_df['PredictedOutcome'] = X_hnc_test_pred_df\n",
    "hnc_X_test_df['PredictedProbability'] = X_hnc_test_proba_df\n",
    "# print(hnc_X_test_df)\n",
    "\n",
    "# calculate c-index\n",
    "hnc_cindex = concordance_index(hnc_X_test_df['SurvivalMonths'], -hnc_X_test_df['PredictedProbability'], hnc_X_test_df['TwoYearHNCDeath']) # the negative value is used for probability, see documentation\n",
    "print(\"c-index=\", hnc_cindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b3cec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run 1000 sample bootstrap to calculate 95% CI for c-index\n",
    "hnc_cindex_score = []\n",
    "n_iterations = 1000\n",
    "for i in range(n_iterations):\n",
    "    time, prob, event = resample(X_hnc_test_cindex['SurvivalMonths'], X_hnc_test_proba_df, y_hnc_test, replace=True)\n",
    "    hnc_ci_score = concordance_index(time, prob, event)\n",
    "    hnc_cindex_score.append(hnc_ci_score)\n",
    "\n",
    "# sns.kdeplot(hnc_cindex_score)\n",
    "# plt.show()\n",
    "\n",
    "# calculate 95% CI of cindex\n",
    "hnc_cindex_25_percentile = np.percentile(hnc_cindex_score, 25)\n",
    "print('25th percentile hnc:', 1-hnc_cindex_25_percentile)\n",
    "hnc_cindex_50_percentile = np.percentile(hnc_cindex_score, 50) # value should be very close to calculated c-index score\n",
    "print('50th percentile hnc:', 1-hnc_cindex_50_percentile)\n",
    "hnc_cindex_75_percentile = np.percentile(hnc_cindex_score, 75)\n",
    "print('75th percentile hnc:', 1-hnc_cindex_75_percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9317d41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "pickle.dump(hnc_grid_search_rf, open('/PATH/TO/FILE.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c7f1cf",
   "metadata": {},
   "source": [
    "# kaplan meier - hnc dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229ba673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset with survival time included for merging to dataset with pred and proba without oversampling\n",
    "X_hnc_surv = completed_hnc_df.drop(axis=1, columns=['PatientID', 'TwoYearHNCDeath'])\n",
    "y_hnc_surv = completed_hnc_df['TwoYearHNCDeath']\n",
    "X_hnc_surv_train_time, X_hnc_surv_test_time, y_hnc_surv_train, y_hnc_surv_test = train_test_split(X_hnc_surv, y_hnc_surv, stratify=y_hnc_surv, random_state=0, test_size = 0.2)\n",
    "# remove survival time from X train and test\n",
    "X_hnc_surv_train = X_hnc_surv_train_time.drop(axis=1, columns=['SurvivalMonths'])\n",
    "# print(X_hnc_surv_train)\n",
    "X_hnc_surv_test = X_hnc_surv_test_time.drop(axis=1, columns=['SurvivalMonths'])\n",
    "# print(X_hnc_surv_test)\n",
    "\n",
    "# use gridsearchCV to find for parameter tuning \n",
    "max_features = [\"sqrt\", \"log2\"]\n",
    "n_estimators = [100, 1000, 10000, 100000]\n",
    "class_weight = [{0:.1, 1:.9}, {0:.2, 1:0.8}, {0:.3, 1:.7}, {0:.4, 1:.6}, {0:.5, 1:.5}]\n",
    "\n",
    "# create parameter dictionary for tuning\n",
    "hnc_surv_rf_param_grid = dict(max_features=max_features,\n",
    "                            n_estimators=n_estimators, \n",
    "                            class_weight=class_weight)\n",
    "\n",
    "# define the gridsearchCV object with 5 CV\n",
    "hnc_surv_grid_search_rf = GridSearchCV(rf, param_grid=hnc_surv_rf_param_grid, cv=5, n_jobs=-1, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9edfb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit the tree gridsearchCV object\n",
    "hnc_surv_grid_search_rf.fit(X_hnc_surv_train, y_hnc_surv_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e47ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best parameters and average accuracy score\n",
    "print(\"Best parameters: {}\".format(hnc_surv_grid_search_rf.best_params_))\n",
    "print(\"Best cross-validation average accuracy score: {:.2f}\".format(hnc_surv_grid_search_rf.best_score_))\n",
    "\n",
    "# predict outcome using tuned on train set\n",
    "y_pred_hnc_surv_rf_grid_search_train = hnc_surv_grid_search_rf.predict(X_hnc_surv_train)\n",
    "# predict probabilities on train set\n",
    "y_prob_hnc_surv_rf_grid_search_train = hnc_surv_grid_search_rf.predict_proba(X_hnc_surv_train)\n",
    "# print(y_prob_hnc_surv_rf_grid_search_train)\n",
    "\n",
    "# calculate percentiles on train set\n",
    "hnc_surv_train_25_percentile = np.percentile (y_prob_hnc_surv_rf_grid_search_train[:,1], 25) # for prediction of class 1 'death'\n",
    "# print('25th percentile:', hnc_surv_train_25_percentile)\n",
    "hnc_surv_train_50_percentile = np.percentile (y_prob_hnc_surv_rf_grid_search_train[:,1], 50)\n",
    "# print('50th percentile:', hnc_surv_train_50_percentile)\n",
    "hnc_surv_train_75_percentile = np.percentile (y_prob_hnc_surv_rf_grid_search_train[:,1], 75)\n",
    "# print('75th percentile:', hnc_surv_train_75_percentile)\n",
    "\n",
    "# predict outcome using tuned model on test set\n",
    "y_pred_hnc_surv_rf_grid_search_test = hnc_surv_grid_search_rf.predict(X_hnc_surv_test)\n",
    "# print(y_pred_hnc_surv_rf_grid_search_test)\n",
    "# predict probabilities on test set\n",
    "y_prob_hnc_surv_rf_grid_search_test = hnc_surv_grid_search_rf.predict_proba(X_hnc_surv_test)\n",
    "# print(y_prob_hnc_surv_rf_grid_search_test[:,1])\n",
    "\n",
    "# calculate percentiles on test set\n",
    "X_hnc_surv_test_25_percentile = np.percentile (y_prob_hnc_surv_rf_grid_search_test[:,1], 25)\n",
    "# print('25th percentile:', X_hnc_surv_test_25_percentile)\n",
    "X_hnc_surv_test_50_percentile = np.percentile (y_prob_hnc_surv_rf_grid_search_test[:,1], 50)\n",
    "# print('50th percentile:', X_hnc_surv_test_50_percentile)\n",
    "X_hnc_surv_test_75_percentile = np.percentile (y_prob_hnc_surv_rf_grid_search_test[:,1], 75)\n",
    "# print('75th percentile:', X_hnc_surv_test_75_percentile)\n",
    "\n",
    "# print the accuracy scores\n",
    "print(\"Accuracy on training set: {:.2f}\".format(accuracy_score(y_hnc_surv_train, y_pred_hnc_surv_rf_grid_search_train)))\n",
    "print(\"Accuracy on test set: {:.2f}\".format(accuracy_score(y_hnc_surv_test, y_pred_hnc_surv_rf_grid_search_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a891a1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance metrics of the tuned model, construct the confusion matrix\n",
    "cm_hnc_surv_rf = confusion_matrix(y_true = y_hnc_surv_test, y_pred = y_pred_hnc_surv_rf_grid_search_test)\n",
    "# plot confusion matrix\n",
    "print(\"Confusion matrix plot of the rf:\")\n",
    "print(cm_hnc_surv_rf)\n",
    "print()\n",
    "print(\"Confusion matrix plot of the rf:\")\n",
    "disease_labels = ['HNC death Absent', 'HNC death Present']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm_hnc_surv_rf)\n",
    "plt.title('Confusion matrix of the rf:')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + disease_labels)\n",
    "ax.set_yticklabels([''] + disease_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44497cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print classification report\n",
    "print(\"Precision, Recall, F1-score for class 0 (HNC death Absent) and class 1 (HNC death Present) classes of the test set:\")\n",
    "print(\"Using random forest model\")\n",
    "print()\n",
    "print(classification_report(y_hnc_surv_test, y_pred_hnc_surv_rf_grid_search_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30aef0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create auc roc curve\n",
    "y_pred_proba_hnc_surv_rf = hnc_surv_grid_search_rf.predict_proba(X_hnc_surv_test)[:,1]\n",
    "print(\"Area under curve for random forest:\")\n",
    "print(metrics.roc_auc_score(y_true = y_hnc_surv_test, y_score = y_pred_hnc_surv_rf_grid_search_test))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_hnc_surv_test, y_pred_hnc_surv_rf_grid_search_test)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='red', lw=2, label='ROC curve random forest')\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f5a83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "pickle.dump(hnc_surv_grid_search_rf, open('/PATH/TO/FILE.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925cd506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pred/proba arrays to dataframes and add column labels\n",
    "X_hnc_surv_test_pred_df = pd.DataFrame([y_pred_hnc_surv_rf_grid_search_test]).transpose()\n",
    "X_hnc_surv_test_pred_df.columns = ['PredictedOutcome']\n",
    "X_hnc_surv_test_proba_df = pd.DataFrame([y_prob_hnc_surv_rf_grid_search_test[:,1]]).transpose()\n",
    "X_hnc_surv_test_proba_df.columns = ['PredictedProbability']\n",
    "\n",
    "# append predicted outcome and probability to test set using indexes\n",
    "hnc_km_df = X_hnc_surv_test.copy()\n",
    "hnc_km_df['SurvivalMonths'] = X_hnc_surv_test_time['SurvivalMonths']\n",
    "hnc_km_df['TwoYearHNCDeath']= y_hnc_surv_test\n",
    "hnc_km_df.reset_index(inplace=True)\n",
    "hnc_km_df['PredictedOutcome'] = X_hnc_surv_test_pred_df\n",
    "hnc_km_df['PredictedProbability'] = X_hnc_surv_test_proba_df\n",
    "# print(hnc_km_df)\n",
    "\n",
    "# create risk group variable, 3=poor prognosis, 2=medium prognosis, 1=good prognosis\n",
    "hnc_km_df['RiskGroup'] = [3 if x<hnc_surv_train_25_percentile else 1 if x>hnc_surv_train_75_percentile else 2 for x in hnc_km_df['PredictedProbability']]\n",
    "# print(hnc_km_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce0939b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot km curve for risk group\n",
    "fig, ax = plt.subplots(figsize=(6,6), dpi=80)\n",
    "df = hnc_km_df\n",
    "ix = df['RiskGroup'] == 'riskgroup'\n",
    "\n",
    "hnc_km_rg1 = KaplanMeierFitter()\n",
    "ax = hnc_km_rg1.fit(df[df[\"RiskGroup\"] == 1]['SurvivalMonths'], df[df[\"RiskGroup\"] == 1]['TwoYearHNCDeath'], label='poor prognosis').plot_survival_function(ax=ax)\n",
    "\n",
    "hnc_km_rg2 = KaplanMeierFitter()\n",
    "ax = hnc_km_rg2.fit(df[df[\"RiskGroup\"] == 2]['SurvivalMonths'], df[df[\"RiskGroup\"] == 2]['TwoYearHNCDeath'], label='medium prognosis').plot_survival_function(ax=ax)\n",
    "\n",
    "hnc_km_rg3 = KaplanMeierFitter()\n",
    "ax = hnc_km_rg3.fit(df[df[\"RiskGroup\"] == 3]['SurvivalMonths'], df[df[\"RiskGroup\"] == 3]['TwoYearHNCDeath'], label='good prognosis').plot_survival_function(ax=ax)\n",
    "\n",
    "from lifelines.plotting import add_at_risk_counts\n",
    "add_at_risk_counts(hnc_km_rg1, hnc_km_rg2, hnc_km_rg3, ax=ax)\n",
    "ax.set_xlabel(\"Survival time (months)\")\n",
    "ax.set_xlim(0, 24) # set x axis to 24 months\n",
    "ax.set_ylabel(\"Survival\")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[::-1], labels[::-1], loc='lower left')\n",
    "plt.tight_layout()\n",
    "\n",
    "# save km figure\n",
    "plt.savefig(\"/PATH/TO/FILE.jpeg\", dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fe7d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print event table for each risk group\n",
    "print(hnc_km_rg1.event_table)\n",
    "print(hnc_km_rg2.event_table)\n",
    "print(hnc_km_rg3.event_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5508857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate log rank statistics\n",
    "hnc_results = multivariate_logrank_test(hnc_km_df['SurvivalMonths'], hnc_km_df['RiskGroup'], hnc_km_df['TwoYearHNCDeath'])\n",
    "hnc_results.print_summary()\n",
    "print(\"p value =\", hnc_results.p_value)        \n",
    "print(\"t statistic =\", hnc_results.test_statistic) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5357899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate c-index\n",
    "hnc_surv_cindex = concordance_index(hnc_km_df['SurvivalMonths'], -hnc_km_df['PredictedProbability'], hnc_km_df['TwoYearHNCDeath'])\n",
    "print(hnc_surv_cindex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f0aeb4",
   "metadata": {},
   "source": [
    "# prediction - hpc dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96792e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate random forest model\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "# split into 80% train and 20% test using oversampled dataset\n",
    "X_hpc_train, X_hpc_test, y_hpc_train, y_hpc_test = train_test_split(X_hpc_smote, y_hpc_smote, stratify=y_hpc_smote, random_state=0, test_size = 0.2)\n",
    "# use gridsearchCV for parameter tuning \n",
    "max_features = [\"sqrt\", \"log2\"]\n",
    "n_estimators = [1000, 10000, 100000]\n",
    "class_weight = [{0:.1, 1:.9}, {0:.2, 1:0.8}, {0:.3, 1:.7}, {0:.4, 1:.6}, {0:.5, 1:.5}]\n",
    "# create parameter dictionary for tuning\n",
    "hpc_rf_param_grid = dict(max_features=max_features,\n",
    "                            n_estimators=n_estimators, \n",
    "                            class_weight=class_weight)\n",
    "# define the gridsearchCV object with 5 CV\n",
    "hpc_grid_search_rf = GridSearchCV(rf, param_grid=hpc_rf_param_grid, cv=5, n_jobs=-1, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b9888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the tree gridsearchCV object\n",
    "hpc_grid_search_rf.fit(X_hpc_train, y_hpc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69af7ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best parameters and average accuracy score\n",
    "print(\"Best parameters: {}\".format(hpc_grid_search_rf.best_params_))\n",
    "print(\"Best cross-validation average accuracy score: {:.2f}\".format(hpc_grid_search_rf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9353110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict outcome on train set\n",
    "y_pred_hpc_rf_grid_search_train = hpc_grid_search_rf.predict(X_hpc_train)\n",
    "# predict probabilities on train set\n",
    "y_prob_hpc_rf_grid_search_train = hpc_grid_search_rf.predict_proba(X_hpc_train)\n",
    "# predict outcome on test set\n",
    "y_pred_hpc_rf_grid_search_test = hpc_grid_search_rf.predict(X_hpc_test)\n",
    "# predict probabilities on test set\n",
    "y_prob_hpc_rf_grid_search_test = hpc_grid_search_rf.predict_proba(X_hpc_test)\n",
    "# print(y_prob_hpc_rf_grid_search_test[:,1])\n",
    "\n",
    "# print the accuracy scores\n",
    "print(\"Accuracy on training set: {:.2f}\".format(accuracy_score(y_hpc_train, y_pred_hpc_rf_grid_search_train)))\n",
    "print(\"Accuracy on test set: {:.2f}\".format(accuracy_score(y_hpc_test, y_pred_hpc_rf_grid_search_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32cfb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance metrics of the tuned model, construct the confusion matrix\n",
    "cm_hpc_rf = confusion_matrix(y_true = y_hpc_test, y_pred = y_pred_hpc_rf_grid_search_test)\n",
    "# plot confusion matrix\n",
    "print(\"Confusion matrix plot of the rf:\")\n",
    "print(cm_hpc_rf)\n",
    "print()\n",
    "print(\"Confusion matrix plot of the rf:\")\n",
    "disease_labels = ['HNC death Absent', 'HNC death Present']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm_hpc_rf)\n",
    "plt.title('Confusion matrix of the rf:')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + disease_labels)\n",
    "ax.set_yticklabels([''] + disease_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8e0629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print classification report\n",
    "print(\"Precision, Recall, F1-score for class 0 (HNC death Absent) and class 1 (HNC death Present) classes of the test set:\")\n",
    "print(\"Using random forest model\")\n",
    "print()\n",
    "print(classification_report(y_hpc_test, y_pred_hpc_rf_grid_search_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5ef61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create auc roc curve\n",
    "y_pred_proba_hpc_rf = hpc_grid_search_rf.predict_proba(X_hpc_test)[:,1]\n",
    "print(\"Area under curve for random forest:\")\n",
    "print(metrics.roc_auc_score(y_true = y_hpc_test, y_score = y_pred_proba_hpc_rf))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_hpc_test, y_pred_proba_hpc_rf)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='red', lw=2, label='ROC curve random forest')\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244271d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate c-index\n",
    "# convert pred/proba arrays to dataframes and add column labels\n",
    "X_hpc_test_pred_df = pd.DataFrame([y_pred_hpc_rf_grid_search_test]).transpose()\n",
    "X_hpc_test_pred_df.columns = ['PredictedOutcome']\n",
    "X_hpc_test_proba_df = pd.DataFrame([y_prob_hpc_rf_grid_search_test[:,1]]).transpose()\n",
    "X_hpc_test_proba_df.columns = ['PredictedProbability']\n",
    "\n",
    "# split dataset to include survival time in X for c-index calculation\n",
    "X_hpc_cindex = completed_hpc_df.drop(axis=1, columns=['PatientID', 'TwoYearHNCDeath'])\n",
    "y_hpc_cindex = completed_hpc_df['TwoYearHNCDeath']\n",
    "# create balanced dataset with survival time\n",
    "smote = SMOTE(random_state=1, k_neighbors=5)\n",
    "X_hpc_cindex_smote, y_hpc_cindex_smote = smote.fit_resample(X_hpc_cindex, y_hpc_cindex)\n",
    "# split the dataset into X and y\n",
    "X_hpc_train_cindex, X_hpc_test_cindex, y_hpc_train_cindex, y_hpc_test_cindex = train_test_split(X_hpc_cindex_smote, y_hpc_cindex_smote, stratify=y_hpc_cindex_smote, random_state=0, test_size = 0.2)\n",
    "\n",
    "# append predicted outcome and probability to test set using indexes\n",
    "hpc_X_test_df = X_hpc_test.copy()\n",
    "hpc_X_test_df['SurvivalMonths'] = X_hpc_test_cindex['SurvivalMonths']\n",
    "hpc_X_test_df['TwoYearHNCDeath']= y_hpc_test\n",
    "hpc_X_test_df.reset_index(inplace=True)\n",
    "hpc_X_test_df['PredictedOutcome'] = X_hpc_test_pred_df\n",
    "hpc_X_test_df['PredictedProbability'] = X_hpc_test_proba_df\n",
    "# print(hpc_X_test_df)\n",
    "\n",
    "# calculate c-index\n",
    "hpc_cindex = concordance_index(hpc_X_test_df['SurvivalMonths'], -hpc_X_test_df['PredictedProbability'], hpc_X_test_df['TwoYearHNCDeath']) # the negative value is used for probability, see documentation\n",
    "print(\"c-index=\", hpc_cindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5c5d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run 1000 sample bootstrap to calculate 95% CI for c-index\n",
    "hpc_cindex_score = []\n",
    "n_iterations = 1000\n",
    "for i in range(n_iterations):\n",
    "    time, prob, event = resample(X_hpc_test_cindex['SurvivalMonths'], X_hpc_test_proba_df, y_hpc_test, replace=True)\n",
    "    hpc_ci_score = concordance_index(time, prob, event)\n",
    "    hpc_cindex_score.append(hpc_ci_score)\n",
    "\n",
    "# sns.kdeplot(hc_cindex_score)\n",
    "# plt.show()\n",
    "\n",
    "# calculate 95% CI of cindex\n",
    "hpc_cindex_25_percentile = np.percentile(hpc_cindex_score, 25)\n",
    "print('25th percentile hpc:', 1-hpc_cindex_25_percentile)\n",
    "hpc_cindex_50_percentile = np.percentile(hpc_cindex_score, 50) # value should be very close to calculated c-index score\n",
    "print('50th percentile hpc:', 1-hpc_cindex_50_percentile)\n",
    "hpc_cindex_75_percentile = np.percentile(hpc_cindex_score, 75)\n",
    "print('75th percentile hpc:', 1-hpc_cindex_75_percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d0a1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "pickle.dump(hpc_grid_search_rf, open('/PATH/TO/FILE.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7cf05b",
   "metadata": {},
   "source": [
    "# kaplan meier - hpc dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed261f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset with survival time included for merging to dataset with pred and proba without oversampling\n",
    "X_hpc_surv = completed_hpc_df.drop(axis=1, columns=['PatientID', 'TumourSite', 'TwoYearHNCDeath'])\n",
    "y_hpc_surv = completed_hpc_df['TwoYearHNCDeath']\n",
    "X_hpc_surv_train_time, X_hpc_surv_test_time, y_hpc_surv_train, y_hpc_surv_test = train_test_split(X_hpc_surv, y_hpc_surv, stratify=y_hpc_surv, random_state=0, test_size = 0.2)\n",
    "# remove survival time from X train and test\n",
    "X_hpc_surv_train = X_hpc_surv_train_time.drop(axis=1, columns=['SurvivalMonths'])\n",
    "# print(X_hpc_surv_train)\n",
    "X_hpc_surv_test = X_hpc_surv_test_time.drop(axis=1, columns=['SurvivalMonths'])\n",
    "# print(X_hpc_surv_test)\n",
    "\n",
    "# use gridsearchCV to find for parameter tuning \n",
    "max_features = [\"sqrt\", \"log2\"]\n",
    "n_estimators = [100, 1000, 10000, 100000]\n",
    "class_weight = [{0:.1, 1:.9}, {0:.2, 1:0.8}, {0:.3, 1:.7}, {0:.4, 1:.6}, {0:.5, 1:.5}]\n",
    "\n",
    "# create parameter dictionary for tuning\n",
    "hpc_surv_rf_param_grid = dict(max_features=max_features,\n",
    "                            n_estimators=n_estimators, \n",
    "                            class_weight=class_weight)\n",
    "\n",
    "# define the gridsearchCV object with 5 CV\n",
    "hpc_surv_grid_search_rf = GridSearchCV(rf, param_grid=hpc_surv_rf_param_grid, cv=5, n_jobs=-1, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfa8d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the tree gridsearchCV object\n",
    "hpc_surv_grid_search_rf.fit(X_hpc_surv_train, y_hpc_surv_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4023b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best parameters and average accuracy score\n",
    "print(\"Best parameters: {}\".format(hpc_surv_grid_search_rf.best_params_))\n",
    "print(\"Best cross-validation average accuracy score: {:.2f}\".format(hpc_surv_grid_search_rf.best_score_))\n",
    "\n",
    "# predict outcome using tuned model on train set\n",
    "y_pred_hpc_surv_rf_grid_search_train = hpc_surv_grid_search_rf.predict(X_hpc_surv_train)\n",
    "# predict probabilities on train set\n",
    "y_prob_hpc_surv_rf_grid_search_train = hpc_surv_grid_search_rf.predict_proba(X_hpc_surv_train)\n",
    "# print(y_prob_hpc_surv_rf_grid_search_train)\n",
    "\n",
    "# calculate percentiles on train set\n",
    "hpc_surv_train_25_percentile = np.percentile (y_prob_hpc_surv_rf_grid_search_train[:,1], 25) # for prediction of class 1 'death'\n",
    "# print('25th percentile:', hpc_surv_train_25_percentile)\n",
    "hpc_surv_train_50_percentile = np.percentile (y_prob_hpc_surv_rf_grid_search_train[:,1], 50)\n",
    "# print('50th percentile:', hpc_surv_train_50_percentile)\n",
    "hpc_surv_train_75_percentile = np.percentile (y_prob_hpc_surv_rf_grid_search_train[:,1], 75)\n",
    "# print('75th percentile:', hpc_surv_train_75_percentile)\n",
    "\n",
    "# predict outcome using tuned model on test set\n",
    "y_pred_hpc_surv_rf_grid_search_test = hpc_surv_grid_search_rf.predict(X_hpc_surv_test)\n",
    "# print(y_pred_hpc_surv_rf_grid_search_test)\n",
    "# predict probabilities on test set\n",
    "y_prob_hpc_surv_rf_grid_search_test = hpc_surv_grid_search_rf.predict_proba(X_hpc_surv_test)\n",
    "# print(y_prob_hpc_surv_rf_grid_search_test[:,1])\n",
    "\n",
    "# calculate percentiles on test set\n",
    "X_hpc_surv_test_25_percentile = np.percentile (y_prob_hpc_surv_rf_grid_search_test[:,1], 25)\n",
    "# print('25th percentile:', X_hpc_surv_test_25_percentile)\n",
    "X_hpc_surv_test_50_percentile = np.percentile (y_prob_hpc_surv_rf_grid_search_test[:,1], 50)\n",
    "# print('50th percentile:', X_hpc_surv_test_50_percentile)\n",
    "X_hpc_surv_test_75_percentile = np.percentile (y_prob_hpc_surv_rf_grid_search_test[:,1], 75)\n",
    "# print('75th percentile:', X_hpc_surv_test_75_percentile)\n",
    "\n",
    "# print the accuracy scores\n",
    "print(\"Accuracy on training set: {:.2f}\".format(accuracy_score(y_hpc_surv_train, y_pred_hpc_surv_rf_grid_search_train)))\n",
    "print(\"Accuracy on test set: {:.2f}\".format(accuracy_score(y_hpc_surv_test, y_pred_hpc_surv_rf_grid_search_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816f019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance metrics of the tuned model, construct the confusion matrix\n",
    "cm_hpc_surv_rf = confusion_matrix(y_true = y_hpc_surv_test, y_pred = y_pred_hpc_surv_rf_grid_search_test)\n",
    "# plot confusion matrix\n",
    "print(\"Confusion matrix plot of the rf:\")\n",
    "print(cm_hpc_surv_rf)\n",
    "print()\n",
    "print(\"Confusion matrix plot of the rf:\")\n",
    "disease_labels = ['HNC death Absent', 'HNC death Present']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm_hpc_surv_rf)\n",
    "plt.title('Confusion matrix of the rf:')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + disease_labels)\n",
    "ax.set_yticklabels([''] + disease_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227d5ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print classification report\n",
    "print(\"Precision, Recall, F1-score for class 0 (HNC death Absent) and class 1 (HNC death Present) classes of the test set:\")\n",
    "print(\"Using random forest model\")\n",
    "print()\n",
    "print(classification_report(y_hpc_surv_test, y_pred_hpc_surv_rf_grid_search_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe148773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create auc roc curve\n",
    "y_pred_proba_hpc_surv_rf = hpc_surv_grid_search_rf.predict_proba(X_hpc_surv_test)[:,1]\n",
    "print(\"Area under curve for random forest:\")\n",
    "print(metrics.roc_auc_score(y_true = y_hpc_surv_test, y_score = y_pred_hpc_surv_rf_grid_search_test))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_hpc_surv_test, y_pred_hpc_surv_rf_grid_search_test)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='red', lw=2, label='ROC curve random forest')\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1d2eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "pickle.dump(hpc_surv_grid_search_rf, open('/PATH/TO/FILE.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9b4597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pred/proba arrays to dataframes and add column labels\n",
    "X_hpc_surv_test_pred_df = pd.DataFrame([y_pred_hpc_surv_rf_grid_search_test]).transpose()\n",
    "X_hpc_surv_test_pred_df.columns = ['PredictedOutcome']\n",
    "X_hpc_surv_test_proba_df = pd.DataFrame([y_prob_hpc_surv_rf_grid_search_test[:,1]]).transpose()\n",
    "X_hpc_surv_test_proba_df.columns = ['PredictedProbability']\n",
    "\n",
    "# append predicted outcome and probability to test set using indexes\n",
    "hpc_km_df = X_hpc_surv_test.copy()\n",
    "hpc_km_df['SurvivalMonths'] = X_hpc_surv_test_time['SurvivalMonths']\n",
    "hpc_km_df['TwoYearHNCDeath']= y_hpc_surv_test\n",
    "hpc_km_df.reset_index(inplace=True)\n",
    "hpc_km_df['PredictedOutcome'] = X_hpc_surv_test_pred_df\n",
    "hpc_km_df['PredictedProbability'] = X_hpc_surv_test_proba_df\n",
    "# print(hpc_km_df)\n",
    "\n",
    "# create risk group variable, 3=poor prognosis, 2=medium prognosis, 1=good prognosis\n",
    "hpc_km_df['RiskGroup'] = [3 if x<hpc_surv_train_25_percentile else 1 if x>hpc_surv_train_75_percentile else 2 for x in hpc_km_df['PredictedProbability']]\n",
    "# print(hpc_km_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e6589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot km curve for risk group\n",
    "fig, ax = plt.subplots(figsize=(6,6), dpi=80)\n",
    "df = hpc_km_df\n",
    "ix = df['RiskGroup'] == 'riskgroup'\n",
    "\n",
    "hpc_km_rg1 = KaplanMeierFitter()\n",
    "ax = hpc_km_rg1.fit(df[df[\"RiskGroup\"] == 1]['SurvivalMonths'], df[df[\"RiskGroup\"] == 1]['TwoYearHNCDeath'], label='poor prognosis').plot_survival_function(ax=ax)\n",
    "\n",
    "hpc_km_rg2 = KaplanMeierFitter()\n",
    "ax = hpc_km_rg2.fit(df[df[\"RiskGroup\"] == 2]['SurvivalMonths'], df[df[\"RiskGroup\"] == 2]['TwoYearHNCDeath'], label='medium prognosis').plot_survival_function(ax=ax)\n",
    "\n",
    "hpc_km_rg3 = KaplanMeierFitter()\n",
    "ax = hpc_km_rg3.fit(df[df[\"RiskGroup\"] == 3]['SurvivalMonths'], df[df[\"RiskGroup\"] == 3]['TwoYearHNCDeath'], label='good prognosis').plot_survival_function(ax=ax)\n",
    "\n",
    "from lifelines.plotting import add_at_risk_counts\n",
    "add_at_risk_counts(hpc_km_rg1, hpc_km_rg2, hpc_km_rg3, ax=ax)\n",
    "ax.set_xlabel(\"Survival time (months)\")\n",
    "ax.set_xlim(0, 24) # set x axis to 24 months\n",
    "ax.set_ylabel(\"Survival\")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[::-1], labels[::-1], loc='lower left')\n",
    "plt.tight_layout()\n",
    "\n",
    "# save km figure\n",
    "plt.savefig(\"/PATH/TO/FILE.jpeg\", dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ba7166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print event table for each risk group\n",
    "print(hpc_km_rg1.event_table)\n",
    "print(hpc_km_rg2.event_table)\n",
    "print(hpc_km_rg3.event_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b13130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate log rank statistics\n",
    "hpc_results = multivariate_logrank_test(hpc_km_df['SurvivalMonths'], hpc_km_df['RiskGroup'], hpc_km_df['TwoYearHNCDeath'])\n",
    "hpc_results.print_summary()\n",
    "print(\"p value =\", hpc_results.p_value)        \n",
    "print(\"t statistic =\", hpc_results.test_statistic) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa42b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate c-index\n",
    "hpc_surv_cindex = concordance_index(hpc_km_df['SurvivalMonths'], -hpc_km_df['PredictedProbability'], hpc_km_df['TwoYearHNCDeath'])\n",
    "print(hpc_surv_cindex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a6542a",
   "metadata": {},
   "source": [
    "# prediction - lyx dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07abe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate random forest model\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "# split into 80% train and 20% test using oversampled dataset\n",
    "X_lyx_train, X_lyx_test, y_lyx_train, y_lyx_test = train_test_split(X_lyx_smote, y_lyx_smote, stratify=y_lyx_smote, random_state=0, test_size = 0.2)\n",
    "# use gridsearchCV for parameter tuning \n",
    "max_features = [\"sqrt\", \"log2\"]\n",
    "n_estimators = [100, 1000, 10000, 100000]\n",
    "class_weight = [{0:.1, 1:.9}, {0:.2, 1:0.8}, {0:.3, 1:.7}, {0:.4, 1:.6}, {0:.5, 1:.5}]\n",
    "# create parameter dictionary for tuning\n",
    "lyx_rf_param_grid = dict(max_features=max_features,\n",
    "                            n_estimators=n_estimators, \n",
    "                            class_weight=class_weight)\n",
    "# define the gridsearchCV object with 5 CV\n",
    "lyx_grid_search_rf = GridSearchCV(rf, param_grid=lyx_rf_param_grid, cv=5, n_jobs=-1, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ac8211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the tree gridsearchCV object\n",
    "lyx_grid_search_rf.fit(X_lyx_train, y_lyx_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602b872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best parameters and average accuracy score\n",
    "print(\"Best parameters: {}\".format(lyx_grid_search_rf.best_params_))\n",
    "print(\"Best cross-validation average accuracy score: {:.2f}\".format(lyx_grid_search_rf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519ccc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict outcome on train set\n",
    "y_pred_lyx_rf_grid_search_train = lyx_grid_search_rf.predict(X_lyx_train)\n",
    "# predict probabilities on train set\n",
    "y_prob_lyx_rf_grid_search_train = lyx_grid_search_rf.predict_proba(X_lyx_train)\n",
    "# predict outcome on test set\n",
    "y_pred_lyx_rf_grid_search_test = lyx_grid_search_rf.predict(X_lyx_test)\n",
    "# predict probabilities on test set\n",
    "y_prob_lyx_rf_grid_search_test = lyx_grid_search_rf.predict_proba(X_lyx_test)\n",
    "# print(y_prob_lyx_rf_grid_search_test[:,1])\n",
    "\n",
    "# print the accuracy scores\n",
    "print(\"Accuracy on training set: {:.2f}\".format(accuracy_score(y_lyx_train, y_pred_lyx_rf_grid_search_train)))\n",
    "print(\"Accuracy on test set: {:.2f}\".format(accuracy_score(y_lyx_test, y_pred_lyx_rf_grid_search_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d2cae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance metrics of the tuned model, construct the confusion matrix\n",
    "cm_lyx_rf = confusion_matrix(y_true = y_lyx_test, y_pred = y_pred_lyx_rf_grid_search_test)\n",
    "# plot confusion matrix\n",
    "print(\"Confusion matrix plot of the rf:\")\n",
    "print(cm_lyx_rf)\n",
    "print()\n",
    "print(\"Confusion matrix plot of the rf:\")\n",
    "disease_labels = ['HNC death Absent', 'HNC death Present']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm_lyx_rf)\n",
    "plt.title('Confusion matrix of the rf:')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + disease_labels)\n",
    "ax.set_yticklabels([''] + disease_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d0d127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print classification report\n",
    "print(\"Precision, Recall, F1-score for class 0 (HNC death Absent) and class 1 (HNC death Present) classes of the test set:\")\n",
    "print(\"Using random forest model\")\n",
    "print()\n",
    "print(classification_report(y_lyx_test, y_pred_lyx_rf_grid_search_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6133d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create auc roc curve\n",
    "y_pred_proba_lyx_rf = lyx_grid_search_rf.predict_proba(X_lyx_test)[:,1]\n",
    "print(\"Area under curve for random forest:\")\n",
    "print(metrics.roc_auc_score(y_true = y_lyx_test, y_score = y_pred_proba_lyx_rf))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_lyx_test, y_pred_proba_lyx_rf)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='red', lw=2, label='ROC curve random forest')\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77404648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate c-index\n",
    "# convert pred/proba arrays to dataframes and add column labels\n",
    "X_lyx_test_pred_df = pd.DataFrame([y_pred_lyx_rf_grid_search_test]).transpose()\n",
    "X_lyx_test_pred_df.columns = ['PredictedOutcome']\n",
    "X_lyx_test_proba_df = pd.DataFrame([y_prob_lyx_rf_grid_search_test[:,1]]).transpose()\n",
    "X_lyx_test_proba_df.columns = ['PredictedProbability']\n",
    "\n",
    "# split dataset to include survival time in X for c-index calculation\n",
    "X_lyx_cindex = completed_lyx_df.drop(axis=1, columns=['PatientID', 'TumourSite', 'TwoYearHNCDeath'])\n",
    "y_lyx_cindex = completed_lyx_df['TwoYearHNCDeath']\n",
    "# create balanced dataset with survival time\n",
    "smote = SMOTE(random_state=1, k_neighbors=5)\n",
    "X_lyx_cindex_smote, y_lyx_cindex_smote = smote.fit_resample(X_lyx_cindex, y_lyx_cindex)\n",
    "# split the dataset into X and y\n",
    "X_lyx_train_cindex, X_lyx_test_cindex, y_lyx_train_cindex, y_lyx_test_cindex = train_test_split(X_lyx_cindex_smote, y_lyx_cindex_smote, stratify=y_lyx_cindex_smote, random_state=0, test_size = 0.2)\n",
    "\n",
    "# append predicted outcome and probability to test set using indexes\n",
    "lyx_X_test_df = X_lyx_test.copy()\n",
    "lyx_X_test_df['SurvivalMonths'] = X_lyx_test_cindex['SurvivalMonths']\n",
    "lyx_X_test_df['TwoYearHNCDeath']= y_lyx_test\n",
    "lyx_X_test_df.reset_index(inplace=True)\n",
    "lyx_X_test_df['PredictedOutcome'] = X_lyx_test_pred_df\n",
    "lyx_X_test_df['PredictedProbability'] = X_lyx_test_proba_df\n",
    "# print(lyx_X_test_df)\n",
    "\n",
    "# calculate c-index\n",
    "lyx_cindex = concordance_index(lyx_X_test_df['SurvivalMonths'], -lyx_X_test_df['PredictedProbability'], lyx_X_test_df['TwoYearHNCDeath']) # the negative value is used for probability, see documentation\n",
    "print(\"c-index=\", lyx_cindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dd0265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run 1000 sample bootstrap to calculate 95% CI for c-index\n",
    "lyx_cindex_score = []\n",
    "n_iterations = 1000\n",
    "for i in range(n_iterations):\n",
    "    time, prob, event = resample(X_lyx_test_cindex['SurvivalMonths'], X_lyx_test_proba_df, y_lyx_test, replace=True)\n",
    "    lyx_ci_score = concordance_index(time, prob, event)\n",
    "    lyx_cindex_score.append(lyx_ci_score)\n",
    "\n",
    "# sns.kdeplot(lyx_cindex_score)\n",
    "# plt.show()\n",
    "\n",
    "# calculate 95% CI of cindex\n",
    "lyx_cindex_25_percentile = np.percentile(lyx_cindex_score, 25)\n",
    "print('25th percentile lyx:', 1-lyx_cindex_25_percentile)\n",
    "lyx_cindex_50_percentile = np.percentile(lyx_cindex_score, 50) # value should be very close to calculated c-index score\n",
    "print('50th percentile lyx:', 1-lyx_cindex_50_percentile)\n",
    "lyx_cindex_75_percentile = np.percentile(lyx_cindex_score, 75)\n",
    "print('75th percentile lyx:', 1-lyx_cindex_75_percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ae4163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "pickle.dump(lyx_grid_search_rf, open('/PATH/TO/FILE.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816233d8",
   "metadata": {},
   "source": [
    "# kaplan meier - lyx dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3fcee9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split dataset with survival time included for merging to dataset with pred and proba without oversampling\n",
    "X_lyx_surv = completed_lyx_df.drop(axis=1, columns=['PatientID', 'TumourSite', 'TwoYearHNCDeath'])\n",
    "y_lyx_surv = completed_lyx_df['TwoYearHNCDeath']\n",
    "X_lyx_surv_train_time, X_lyx_surv_test_time, y_lyx_surv_train, y_lyx_surv_test = train_test_split(X_lyx_surv, y_lyx_surv, stratify=y_lyx_surv, random_state=0, test_size = 0.2)\n",
    "# remove survival time from X train and test\n",
    "X_lyx_surv_train = X_lyx_surv_train_time.drop(axis=1, columns=['SurvivalMonths'])\n",
    "# print(X_lyx_surv_train)\n",
    "X_lyx_surv_test = X_lyx_surv_test_time.drop(axis=1, columns=['SurvivalMonths'])\n",
    "# print(X_lyx_surv_test)\n",
    "\n",
    "# use gridsearchCV to find for parameter tuning \n",
    "max_features = [\"sqrt\", \"log2\"]\n",
    "n_estimators = [100, 1000, 10000, 100000]\n",
    "class_weight = [{0:.1, 1:.9}, {0:.2, 1:0.8}, {0:.3, 1:.7}, {0:.4, 1:.6}, {0:.5, 1:.5}]\n",
    "\n",
    "# create parameter dictionary for tuning\n",
    "lyx_surv_rf_param_grid = dict(max_features=max_features,\n",
    "                            n_estimators=n_estimators, \n",
    "                            class_weight=class_weight)\n",
    "\n",
    "# define the gridsearchCV object with 5 CV\n",
    "lyx_surv_grid_search_rf = GridSearchCV(rf, param_grid=lyx_surv_rf_param_grid, cv=5, n_jobs=-1, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe6270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the tree gridsearchCV object\n",
    "lyx_surv_grid_search_rf.fit(X_lyx_surv_train, y_lyx_surv_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4e9b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best parameters and average accuracy score\n",
    "print(\"Best parameters: {}\".format(lyx_surv_grid_search_rf.best_params_))\n",
    "print(\"Best cross-validation average accuracy score: {:.2f}\".format(lyx_surv_grid_search_rf.best_score_))\n",
    "\n",
    "# predict outcome using tuned model on train set\n",
    "y_pred_lyx_surv_rf_grid_search_train = lyx_surv_grid_search_rf.predict(X_lyx_surv_train)\n",
    "# predict probabilities on train set\n",
    "y_prob_lyx_surv_rf_grid_search_train = lyx_surv_grid_search_rf.predict_proba(X_lyx_surv_train)\n",
    "# print(y_prob_lyx_surv_rf_grid_search_train)\n",
    "\n",
    "# calculate percentiles on train set\n",
    "lyx_surv_train_25_percentile = np.percentile (y_prob_lyx_surv_rf_grid_search_train[:,1], 25) # for prediction of class 1 'death'\n",
    "# print('25th percentile:', lyx_surv_train_25_percentile)\n",
    "lyx_surv_train_50_percentile = np.percentile (y_prob_lyx_surv_rf_grid_search_train[:,1], 50)\n",
    "# print('50th percentile:', lyx_surv_train_50_percentile)\n",
    "lyx_surv_train_75_percentile = np.percentile (y_prob_lyx_surv_rf_grid_search_train[:,1], 75)\n",
    "# print('75th percentile:', lyx_surv_train_75_percentile)\n",
    "\n",
    "# predict outcome using tuned model on test set\n",
    "y_pred_lyx_surv_rf_grid_search_test = lyx_surv_grid_search_rf.predict(X_lyx_surv_test)\n",
    "# print(y_pred_lyx_surv_rf_grid_search_test)\n",
    "# predict probabilities on test set\n",
    "y_prob_lyx_surv_rf_grid_search_test = lyx_surv_grid_search_rf.predict_proba(X_lyx_surv_test)\n",
    "# print(y_prob_lyx_surv_rf_grid_search_test[:,1])\n",
    "\n",
    "# calculate percentiles on test set\n",
    "X_lyx_surv_test_25_percentile = np.percentile (y_prob_lyx_surv_rf_grid_search_test[:,1], 25)\n",
    "# print('25th percentile:', X_lyx_surv_test_25_percentile)\n",
    "X_lyx_surv_test_50_percentile = np.percentile (y_prob_lyx_surv_rf_grid_search_test[:,1], 50)\n",
    "# print('50th percentile:', X_lyx_surv_test_50_percentile)\n",
    "X_lyx_surv_test_75_percentile = np.percentile (y_prob_lyx_surv_rf_grid_search_test[:,1], 75)\n",
    "# print('75th percentile:', X_lyx_surv_test_75_percentile)\n",
    "\n",
    "# print the accuracy scores\n",
    "print(\"Accuracy on training set: {:.2f}\".format(accuracy_score(y_lyx_surv_train, y_pred_lyx_surv_rf_grid_search_train)))\n",
    "print(\"Accuracy on test set: {:.2f}\".format(accuracy_score(y_lyx_surv_test, y_pred_lyx_surv_rf_grid_search_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54a0e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance metrics of the tuned model, construct the confusion matrix\n",
    "cm_lyx_surv_rf = confusion_matrix(y_true = y_lyx_surv_test, y_pred = y_pred_lyx_surv_rf_grid_search_test)\n",
    "# plot confusion matrix\n",
    "print(\"Confusion matrix plot of the rf:\")\n",
    "print(cm_lyx_surv_rf)\n",
    "print()\n",
    "print(\"Confusion matrix plot of the rf:\")\n",
    "disease_labels = ['HNC death Absent', 'HNC death Present']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm_lyx_surv_rf)\n",
    "plt.title('Confusion matrix of the rf:')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + disease_labels)\n",
    "ax.set_yticklabels([''] + disease_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d610257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print classification report\n",
    "print(\"Precision, Recall, F1-score for class 0 (HNC death Absent) and class 1 (HNC death Present) classes of the test set:\")\n",
    "print(\"Using random forest model\")\n",
    "print()\n",
    "print(classification_report(y_lyx_surv_test, y_pred_lyx_surv_rf_grid_search_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4b6995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create auc roc curve\n",
    "y_pred_proba_lyx_surv_rf = lyx_surv_grid_search_rf.predict_proba(X_lyx_surv_test)[:,1]\n",
    "print(\"Area under curve for random forest:\")\n",
    "print(metrics.roc_auc_score(y_true = y_lyx_surv_test, y_score = y_pred_lyx_surv_rf_grid_search_test))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_lyx_surv_test, y_pred_lyx_surv_rf_grid_search_test)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='red', lw=2, label='ROC curve random forest')\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01434e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "pickle.dump(lyx_surv_grid_search_rf, open('/PATH/TO/FILE.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07974046",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert pred/proba arrays to dataframes and add column labels\n",
    "X_lyx_surv_test_pred_df = pd.DataFrame([y_pred_lyx_surv_rf_grid_search_test]).transpose()\n",
    "X_lyx_surv_test_pred_df.columns = ['PredictedOutcome']\n",
    "X_lyx_surv_test_proba_df = pd.DataFrame([y_prob_lyx_surv_rf_grid_search_test[:,1]]).transpose()\n",
    "X_lyx_surv_test_proba_df.columns = ['PredictedProbability']\n",
    "\n",
    "# append predicted outcome and probability to test set using indexes\n",
    "lyx_km_df = X_lyx_surv_test.copy()\n",
    "lyx_km_df['SurvivalMonths'] = X_lyx_surv_test_time['SurvivalMonths']\n",
    "lyx_km_df['TwoYearHNCDeath']= y_lyx_surv_test\n",
    "lyx_km_df.reset_index(inplace=True)\n",
    "lyx_km_df['PredictedOutcome'] = X_lyx_surv_test_pred_df\n",
    "lyx_km_df['PredictedProbability'] = X_lyx_surv_test_proba_df\n",
    "# print(lyx_km_df)\n",
    "\n",
    "# create risk group variable, 3=poor prognosis, 2=medium prognosis, 1=good prognosis\n",
    "lyx_km_df['RiskGroup'] = [3 if x<lyx_surv_train_25_percentile else 1 if x>lyx_surv_train_75_percentile else 2 for x in lyx_km_df['PredictedProbability']]\n",
    "# print(lyx_km_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11013bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot km curve for risk group\n",
    "fig, ax = plt.subplots(figsize=(6,6), dpi=80)\n",
    "df = lyx_km_df\n",
    "ix = df['RiskGroup'] == 'riskgroup'\n",
    "\n",
    "lyx_km_rg1 = KaplanMeierFitter()\n",
    "ax = lyx_km_rg1.fit(df[df[\"RiskGroup\"] == 1]['SurvivalMonths'], df[df[\"RiskGroup\"] == 1]['TwoYearHNCDeath'], label='poor prognosis').plot_survival_function(ax=ax)\n",
    "\n",
    "lyx_km_rg2 = KaplanMeierFitter()\n",
    "ax = lyx_km_rg2.fit(df[df[\"RiskGroup\"] == 2]['SurvivalMonths'], df[df[\"RiskGroup\"] == 2]['TwoYearHNCDeath'], label='medium prognosis').plot_survival_function(ax=ax)\n",
    "\n",
    "lyx_km_rg3 = KaplanMeierFitter()\n",
    "ax = lyx_km_rg3.fit(df[df[\"RiskGroup\"] == 3]['SurvivalMonths'], df[df[\"RiskGroup\"] == 3]['TwoYearHNCDeath'], label='good prognosis').plot_survival_function(ax=ax)\n",
    "\n",
    "from lifelines.plotting import add_at_risk_counts\n",
    "add_at_risk_counts(lyx_km_rg1, lyx_km_rg2, lyx_km_rg3, ax=ax)\n",
    "ax.set_xlabel(\"Survival time (months)\")\n",
    "ax.set_xlim(0, 24) # set x axis to 24 months\n",
    "ax.set_ylabel(\"Survival\")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[::-1], labels[::-1], loc='lower left')\n",
    "plt.tight_layout()\n",
    "\n",
    "# save km figure\n",
    "plt.savefig(\"/PATH/TO/FILE.jpeg\", dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b2b3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print event table for each risk group\n",
    "print(lyx_km_rg1.event_table)\n",
    "print(lyx_km_rg2.event_table)\n",
    "print(lyx_km_rg3.event_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bd6cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate log rank statistics\n",
    "lyx_results = multivariate_logrank_test(lyx_km_df['SurvivalMonths'], lyx_km_df['RiskGroup'], lyx_km_df['TwoYearHNCDeath'])\n",
    "lyx_results.print_summary()\n",
    "print(\"p value =\", lyx_results.p_value)        \n",
    "print(\"t statistic =\", lyx_results.test_statistic) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a029302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate c-index\n",
    "lyx_surv_cindex = concordance_index(lyx_km_df['SurvivalMonths'], -lyx_km_df['PredictedProbability'], lyx_km_df['TwoYearHNCDeath'])\n",
    "print(lyx_surv_cindex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4999f93b",
   "metadata": {},
   "source": [
    "# prediction - npc dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f89a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate random forest model\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "# split into 80% train and 20% test using oversampled dataset\n",
    "X_npc_train, X_npc_test, y_npc_train, y_npc_test = train_test_split(X_npc_smote, y_npc_smote, stratify=y_npc_smote, random_state=0, test_size = 0.2)\n",
    "# use gridsearchCV for parameter tuning \n",
    "max_features = [\"sqrt\", \"log2\"]\n",
    "n_estimators = [1000, 10000, 100000]\n",
    "class_weight = [{0:.1, 1:.9}, {0:.2, 1:0.8}, {0:.3, 1:.7}, {0:.4, 1:.6}, {0:.5, 1:.5}]\n",
    "# create parameter dictionary for tuning\n",
    "npc_rf_param_grid = dict(max_features=max_features,\n",
    "                            n_estimators=n_estimators, \n",
    "                            class_weight=class_weight)\n",
    "# define the gridsearchCV object with 5 CV\n",
    "npc_grid_search_rf = GridSearchCV(rf, param_grid=npc_rf_param_grid, cv=5, n_jobs=-1, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80568970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the tree gridsearchCV object\n",
    "npc_grid_search_rf.fit(X_npc_train, y_npc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c8658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best parameters and average accuracy score\n",
    "print(\"Best parameters: {}\".format(npc_grid_search_rf.best_params_))\n",
    "print(\"Best cross-validation average accuracy score: {:.2f}\".format(npc_grid_search_rf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804513f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict outcome on train set\n",
    "y_pred_npc_rf_grid_search_train = npc_grid_search_rf.predict(X_npc_train)\n",
    "# predict probabilities on train set\n",
    "y_prob_npc_rf_grid_search_train = npc_grid_search_rf.predict_proba(X_npc_train)\n",
    "# predict outcome on test set\n",
    "y_pred_npc_rf_grid_search_test = npc_grid_search_rf.predict(X_npc_test)\n",
    "# predict probabilities on test set\n",
    "y_prob_npc_rf_grid_search_test = npc_grid_search_rf.predict_proba(X_npc_test)\n",
    "# print(y_prob_npc_rf_grid_search_test[:,1])\n",
    "\n",
    "# print the accuracy scores\n",
    "print(\"Accuracy on training set: {:.2f}\".format(accuracy_score(y_npc_train, y_pred_npc_rf_grid_search_train)))\n",
    "print(\"Accuracy on test set: {:.2f}\".format(accuracy_score(y_npc_test, y_pred_npc_rf_grid_search_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a1e77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance metrics of the tuned model, construct the confusion matrix\n",
    "cm_npc_rf = confusion_matrix(y_true = y_npc_test, y_pred = y_pred_npc_rf_grid_search_test)\n",
    "# plot confusion matrix\n",
    "print(\"Confusion matrix plot of the rf:\")\n",
    "print(cm_npc_rf)\n",
    "print()\n",
    "print(\"Confusion matrix plot of the rf:\")\n",
    "disease_labels = ['HNC death Absent', 'HNC death Present']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm_npc_rf)\n",
    "plt.title('Confusion matrix of the rf:')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + disease_labels)\n",
    "ax.set_yticklabels([''] + disease_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9af677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print classification report\n",
    "print(\"Precision, Recall, F1-score for class 0 (HNC death Absent) and class 1 (HNC death Present) classes of the test set:\")\n",
    "print(\"Using random forest model\")\n",
    "print()\n",
    "print(classification_report(y_npc_test, y_pred_npc_rf_grid_search_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4961ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create auc roc curve\n",
    "y_pred_proba_npc_rf = npc_grid_search_rf.predict_proba(X_npc_test)[:,1]\n",
    "print(\"Area under curve for random forest:\")\n",
    "print(metrics.roc_auc_score(y_true = y_npc_test, y_score = y_pred_proba_npc_rf))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_npc_test, y_pred_proba_npc_rf)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='red', lw=2, label='ROC curve random forest')\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91915b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate c-index\n",
    "# convert pred/proba arrays to dataframes and add column labels\n",
    "X_npc_test_pred_df = pd.DataFrame([y_pred_npc_rf_grid_search_test]).transpose()\n",
    "X_npc_test_pred_df.columns = ['PredictedOutcome']\n",
    "X_npc_test_proba_df = pd.DataFrame([y_prob_npc_rf_grid_search_test[:,1]]).transpose()\n",
    "X_npc_test_proba_df.columns = ['PredictedProbability']\n",
    "\n",
    "# split dataset to include survival time in X for c-index calculation\n",
    "X_npc_cindex = completed_npc_df.drop(axis=1, columns=['PatientID', 'TumourSite', 'TwoYearHNCDeath'])\n",
    "y_npc_cindex = completed_npc_df['TwoYearHNCDeath']\n",
    "# create balanced dataset with survival time\n",
    "smote = SMOTE(random_state=1, k_neighbors=5)\n",
    "X_npc_cindex_smote, y_npc_cindex_smote = smote.fit_resample(X_npc_cindex, y_npc_cindex)\n",
    "# split the dataset into X and y\n",
    "X_npc_train_cindex, X_npc_test_cindex, y_npc_train_cindex, y_npc_test_cindex = train_test_split(X_npc_cindex_smote, y_npc_cindex_smote, stratify=y_npc_cindex_smote, random_state=0, test_size = 0.2)\n",
    "\n",
    "# append predicted outcome and probability to test set using indexes\n",
    "npc_X_test_df = X_npc_test.copy()\n",
    "npc_X_test_df['SurvivalMonths'] = X_npc_test_cindex['SurvivalMonths']\n",
    "npc_X_test_df['TwoYearHNCDeath']= y_npc_test\n",
    "npc_X_test_df.reset_index(inplace=True)\n",
    "npc_X_test_df['PredictedOutcome'] = X_npc_test_pred_df\n",
    "npc_X_test_df['PredictedProbability'] = X_npc_test_proba_df\n",
    "# print(npc_X_test_df)\n",
    "\n",
    "# calculate c-index\n",
    "npc_cindex = concordance_index(npc_X_test_df['SurvivalMonths'], -npc_X_test_df['PredictedProbability'], npc_X_test_df['TwoYearHNCDeath']) # the negative value is used for probability, see documentation\n",
    "print(\"c-index=\", npc_cindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dfc12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run 1000 sample bootstrap to calculate 95% CI for c-index\n",
    "npc_cindex_score = []\n",
    "n_iterations = 1000\n",
    "for i in range(n_iterations):\n",
    "    time, prob, event = resample(X_npc_test_cindex['SurvivalMonths'], X_npc_test_proba_df, y_npc_test, replace=True)\n",
    "    npc_ci_score = concordance_index(time, prob, event)\n",
    "    npc_cindex_score.append(npc_ci_score)\n",
    "\n",
    "# sns.kdeplot(npc_cindex_score)\n",
    "# plt.show()\n",
    "\n",
    "# calculate 95% CI of cindex\n",
    "npc_cindex_25_percentile = np.percentile(npc_cindex_score, 25)\n",
    "print('25th percentile npc:', 1-npc_cindex_25_percentile)\n",
    "npc_cindex_50_percentile = np.percentile(npc_cindex_score, 50) # value should be very close to calculated c-index score\n",
    "print('50th percentile npc:', 1-npc_cindex_50_percentile)\n",
    "npc_cindex_75_percentile = np.percentile(npc_cindex_score, 75)\n",
    "print('75th percentile npc:', 1-npc_cindex_75_percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3518311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "pickle.dump(npc_grid_search_rf, open('/PATH/TO/FILE.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d229d21d",
   "metadata": {},
   "source": [
    "# kaplan meier - npc dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0c6a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset with survival time included for merging to dataset with pred and proba without oversampling\n",
    "X_npc_surv = completed_npc_df.drop(axis=1, columns=['PatientID', 'TumourSite', 'TwoYearHNCDeath'])\n",
    "y_npc_surv = completed_npc_df['TwoYearHNCDeath']\n",
    "X_npc_surv_train_time, X_npc_surv_test_time, y_npc_surv_train, y_npc_surv_test = train_test_split(X_npc_surv, y_npc_surv, stratify=y_npc_surv, random_state=0, test_size = 0.2)\n",
    "# remove survival time from X train and test\n",
    "X_npc_surv_train = X_npc_surv_train_time.drop(axis=1, columns=['SurvivalMonths'])\n",
    "# print(X_npc_surv_train)\n",
    "X_npc_surv_test = X_npc_surv_test_time.drop(axis=1, columns=['SurvivalMonths'])\n",
    "# print(X_npc_surv_test)\n",
    "\n",
    "# use gridsearchCV to find for parameter tuning \n",
    "max_features = [\"sqrt\", \"log2\"]\n",
    "n_estimators = [100, 1000, 10000, 100000]\n",
    "class_weight = [{0:.1, 1:.9}, {0:.2, 1:0.8}, {0:.3, 1:.7}, {0:.4, 1:.6}, {0:.5, 1:.5}]\n",
    "\n",
    "# create parameter dictionary for tuning\n",
    "npc_surv_rf_param_grid = dict(max_features=max_features,\n",
    "                            n_estimators=n_estimators, \n",
    "                            class_weight=class_weight)\n",
    "\n",
    "# define the gridsearchCV object with 5 CV\n",
    "npc_surv_grid_search_rf = GridSearchCV(rf, param_grid=npc_surv_rf_param_grid, cv=5, n_jobs=-1, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805e539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the tree gridsearchCV object\n",
    "npc_surv_grid_search_rf.fit(X_npc_surv_train, y_npc_surv_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b0d263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best parameters and average accuracy score\n",
    "print(\"Best parameters: {}\".format(npc_surv_grid_search_rf.best_params_))\n",
    "print(\"Best cross-validation average accuracy score: {:.2f}\".format(npc_surv_grid_search_rf.best_score_))\n",
    "\n",
    "# predict outcome using tuned model on train set\n",
    "y_pred_npc_surv_rf_grid_search_train = npc_surv_grid_search_rf.predict(X_npc_surv_train)\n",
    "# predict probabilities on train set\n",
    "y_prob_npc_surv_rf_grid_search_train = npc_surv_grid_search_rf.predict_proba(X_npc_surv_train)\n",
    "# print(y_prob_npc_surv_rf_grid_search_train)\n",
    "\n",
    "# calculate percentiles on train set\n",
    "npc_surv_train_25_percentile = np.percentile (y_prob_npc_surv_rf_grid_search_train[:,1], 25) # for prediction of class 1 'death'\n",
    "# print('25th percentile:', npc_surv_train_25_percentile)\n",
    "npc_surv_train_50_percentile = np.percentile (y_prob_npc_surv_rf_grid_search_train[:,1], 50)\n",
    "# print('50th percentile:', npc_surv_train_50_percentile)\n",
    "npc_surv_train_75_percentile = np.percentile (y_prob_npc_surv_rf_grid_search_train[:,1], 75)\n",
    "# print('75th percentile:', npc_surv_train_75_percentile)\n",
    "\n",
    "# predict outcome using tuned model on test set\n",
    "y_pred_npc_surv_rf_grid_search_test = npc_surv_grid_search_rf.predict(X_npc_surv_test)\n",
    "# print(y_pred_npc_surv_rf_grid_search_test)\n",
    "# predict probabilities on test set\n",
    "y_prob_npc_surv_rf_grid_search_test = npc_surv_grid_search_rf.predict_proba(X_npc_surv_test)\n",
    "# print(y_prob_npc_surv_rf_grid_search_test[:,1])\n",
    "\n",
    "# calculate percentiles on test set\n",
    "X_npc_surv_test_25_percentile = np.percentile (y_prob_npc_surv_rf_grid_search_test[:,1], 25)\n",
    "# print('25th percentile:', X_npc_surv_test_25_percentile)\n",
    "X_npc_surv_test_50_percentile = np.percentile (y_prob_npc_surv_rf_grid_search_test[:,1], 50)\n",
    "# print('50th percentile:', X_npc_surv_test_50_percentile)\n",
    "X_npc_surv_test_75_percentile = np.percentile (y_prob_npc_surv_rf_grid_search_test[:,1], 75)\n",
    "# print('75th percentile:', X_npc_surv_test_75_percentile)\n",
    "\n",
    "# print the accuracy scores\n",
    "print(\"Accuracy on training set: {:.2f}\".format(accuracy_score(y_npc_surv_train, y_pred_npc_surv_rf_grid_search_train)))\n",
    "print(\"Accuracy on test set: {:.2f}\".format(accuracy_score(y_npc_surv_test, y_pred_npc_surv_rf_grid_search_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf727d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance metrics of the tuned model, construct the confusion matrix\n",
    "cm_npc_surv_rf = confusion_matrix(y_true = y_npc_surv_test, y_pred = y_pred_npc_surv_rf_grid_search_test)\n",
    "# plot confusion matrix\n",
    "print(\"Confusion matrix plot of the rf:\")\n",
    "print(cm_npc_surv_rf)\n",
    "print()\n",
    "print(\"Confusion matrix plot of the rf:\")\n",
    "disease_labels = ['HNC death Absent', 'HNC death Present']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm_npc_surv_rf)\n",
    "plt.title('Confusion matrix of the rf:')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + disease_labels)\n",
    "ax.set_yticklabels([''] + disease_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb555f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print classification report\n",
    "print(\"Precision, Recall, F1-score for class 0 (HNC death Absent) and class 1 (HNC death Present) classes of the test set:\")\n",
    "print(\"Using random forest model\")\n",
    "print()\n",
    "print(classification_report(y_npc_surv_test, y_pred_npc_surv_rf_grid_search_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1c9567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create auc roc curve\n",
    "y_pred_proba_npc_surv_rf = npc_surv_grid_search_rf.predict_proba(X_npc_surv_test)[:,1]\n",
    "print(\"Area under curve for random forest:\")\n",
    "print(metrics.roc_auc_score(y_true = y_npc_surv_test, y_score = y_pred_npc_surv_rf_grid_search_test))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_npc_surv_test, y_pred_npc_surv_rf_grid_search_test)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='red', lw=2, label='ROC curve random forest')\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "pickle.dump(npc_surv_grid_search_rf, open('/PATH/TO/FILE.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b66bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pred/proba arrays to dataframes and add column labels\n",
    "X_npc_surv_test_pred_df = pd.DataFrame([y_pred_npc_surv_rf_grid_search_test]).transpose()\n",
    "X_npc_surv_test_pred_df.columns = ['PredictedOutcome']\n",
    "X_npc_surv_test_proba_df = pd.DataFrame([y_prob_npc_surv_rf_grid_search_test[:,1]]).transpose()\n",
    "X_npc_surv_test_proba_df.columns = ['PredictedProbability']\n",
    "\n",
    "# append predicted outcome and probability to test set using indexes\n",
    "npc_km_df = X_npc_surv_test.copy()\n",
    "npc_km_df['SurvivalMonths'] = X_npc_surv_test_time['SurvivalMonths']\n",
    "npc_km_df['TwoYearHNCDeath']= y_npc_surv_test\n",
    "npc_km_df.reset_index(inplace=True)\n",
    "npc_km_df['PredictedOutcome'] = X_npc_surv_test_pred_df\n",
    "npc_km_df['PredictedProbability'] = X_npc_surv_test_proba_df\n",
    "# print(npc_km_df)\n",
    "\n",
    "# create risk group variable, 3=poor prognosis, 2=medium prognosis, 1=good prognosis\n",
    "npc_km_df['RiskGroup'] = [3 if x<npc_surv_train_25_percentile else 1 if x>npc_surv_train_75_percentile else 2 for x in npc_km_df['PredictedProbability']]\n",
    "# print(npc_km_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878af2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot km curve for risk group\n",
    "fig, ax = plt.subplots(figsize=(6,6), dpi=80)\n",
    "df = npc_km_df\n",
    "ix = df['RiskGroup'] == 'riskgroup'\n",
    "\n",
    "npc_km_rg1 = KaplanMeierFitter()\n",
    "ax = npc_km_rg1.fit(df[df[\"RiskGroup\"] == 1]['SurvivalMonths'], df[df[\"RiskGroup\"] == 1]['TwoYearHNCDeath'], label='poor prognosis').plot_survival_function(ax=ax)\n",
    "\n",
    "npc_km_rg2 = KaplanMeierFitter()\n",
    "ax = npc_km_rg2.fit(df[df[\"RiskGroup\"] == 2]['SurvivalMonths'], df[df[\"RiskGroup\"] == 2]['TwoYearHNCDeath'], label='medium prognosis').plot_survival_function(ax=ax)\n",
    "\n",
    "# npc_km_rg3 = KaplanMeierFitter()\n",
    "# ax = npc_km_rg3.fit(df[df[\"RiskGroup\"] == 3]['SurvivalMonths'], df[df[\"RiskGroup\"] == 3]['TwoYearHNCDeath'], label='good prognosis').plot_survival_function(ax=ax)\n",
    "\n",
    "from lifelines.plotting import add_at_risk_counts\n",
    "# add_at_risk_counts(npc_km_rg1, npc_km_rg2, npc_km_rg3, ax=ax)\n",
    "add_at_risk_counts(npc_km_rg1, npc_km_rg2, ax=ax)\n",
    "ax.set_xlabel(\"Survival time (months)\")\n",
    "ax.set_xlim(0, 24) # set x axis to 24 months\n",
    "ax.set_ylabel(\"Survival\")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[::-1], labels[::-1], loc='lower left')\n",
    "plt.tight_layout()\n",
    "\n",
    "# save km figure\n",
    "plt.savefig(\"/PATH/TO/FILE.jpeg\", dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b81288d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print event table for each risk group\n",
    "print(npc_km_rg1.event_table)\n",
    "print(npc_km_rg2.event_table)\n",
    "# print(npc_km_rg3.event_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130d2cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate log rank statistics\n",
    "npc_results = multivariate_logrank_test(npc_km_df['SurvivalMonths'], npc_km_df['RiskGroup'], npc_km_df['TwoYearHNCDeath'])\n",
    "npc_results.print_summary()\n",
    "print(\"p value =\", npc_results.p_value)        \n",
    "print(\"t statistic =\", npc_results.test_statistic) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cc7a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate c-index\n",
    "npc_surv_cindex = concordance_index(npc_km_df['SurvivalMonths'], -npc_km_df['PredictedProbability'], npc_km_df['TwoYearHNCDeath'])\n",
    "print(npc_surv_cindex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d8794d",
   "metadata": {},
   "source": [
    "# prediction - occ dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e10f03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate random forest model\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "# split into 80% train and 20% test using oversampled dataset\n",
    "X_occ_train, X_occ_test, y_occ_train, y_occ_test = train_test_split(X_occ_smote, y_occ_smote, stratify=y_occ_smote, random_state=0, test_size = 0.2)\n",
    "# use gridsearchCV for parameter tuning \n",
    "max_features = [\"sqrt\", \"log2\"]\n",
    "n_estimators = [1000, 10000, 100000]\n",
    "class_weight = [{0:.1, 1:.9}, {0:.2, 1:0.8}, {0:.3, 1:.7}, {0:.4, 1:.6}, {0:.5, 1:.5}]\n",
    "# create parameter dictionary for tuning\n",
    "occ_rf_param_grid = dict(max_features=max_features,\n",
    "                            n_estimators=n_estimators, \n",
    "                            class_weight=class_weight)\n",
    "# define the gridsearchCV object with 5 CV\n",
    "occ_grid_search_rf = GridSearchCV(rf, param_grid=occ_rf_param_grid, cv=5, n_jobs=-1, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb76454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the tree gridsearchCV object\n",
    "occ_grid_search_rf.fit(X_occ_train, y_occ_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70c96b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best parameters and average accuracy score\n",
    "print(\"Best parameters: {}\".format(occ_grid_search_rf.best_params_))\n",
    "print(\"Best cross-validation average accuracy score: {:.2f}\".format(occ_grid_search_rf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5960dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict outcome on train set\n",
    "y_pred_occ_rf_grid_search_train = occ_grid_search_rf.predict(X_occ_train)\n",
    "# predict probabilities on train set\n",
    "y_prob_occ_rf_grid_search_train = occ_grid_search_rf.predict_proba(X_occ_train)\n",
    "# predict outcome on test set\n",
    "y_pred_occ_rf_grid_search_test = occ_grid_search_rf.predict(X_occ_test)\n",
    "# predict probabilities on test set\n",
    "y_prob_occ_rf_grid_search_test = occ_grid_search_rf.predict_proba(X_occ_test)\n",
    "# print(y_prob_occ_rf_grid_search_test[:,1])\n",
    "\n",
    "# print the accuracy scores\n",
    "print(\"Accuracy on training set: {:.2f}\".format(accuracy_score(y_occ_train, y_pred_occ_rf_grid_search_train)))\n",
    "print(\"Accuracy on test set: {:.2f}\".format(accuracy_score(y_occ_test, y_pred_occ_rf_grid_search_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05fd86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance metrics of the tuned model, construct the confusion matrix\n",
    "cm_occ_rf = confusion_matrix(y_true = y_occ_test, y_pred = y_pred_occ_rf_grid_search_test)\n",
    "# plot confusion matrix\n",
    "print(\"Confusion matrix plot of the rf:\")\n",
    "print(cm_occ_rf)\n",
    "print()\n",
    "print(\"Confusion matrix plot of the rf:\")\n",
    "disease_labels = ['HNC death Absent', 'HNC death Present']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm_occ_rf)\n",
    "plt.title('Confusion matrix of the rf:')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + disease_labels)\n",
    "ax.set_yticklabels([''] + disease_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17af3c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print classification report\n",
    "print(\"Precision, Recall, F1-score for class 0 (HNC death Absent) and class 1 (HNC death Present) classes of the test set:\")\n",
    "print(\"Using random forest model\")\n",
    "print()\n",
    "print(classification_report(y_occ_test, y_pred_occ_rf_grid_search_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710b0d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create auc roc curve\n",
    "y_pred_proba_occ_rf = occ_grid_search_rf.predict_proba(X_occ_test)[:,1]\n",
    "print(\"Area under curve for random forest:\")\n",
    "print(metrics.roc_auc_score(y_true = y_occ_test, y_score = y_pred_proba_occ_rf))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_occ_test, y_pred_proba_occ_rf)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='red', lw=2, label='ROC curve random forest')\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e471d70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate c-index\n",
    "# convert pred/proba arrays to dataframes and add column labels\n",
    "X_occ_test_pred_df = pd.DataFrame([y_pred_occ_rf_grid_search_test]).transpose()\n",
    "X_occ_test_pred_df.columns = ['PredictedOutcome']\n",
    "X_occ_test_proba_df = pd.DataFrame([y_prob_occ_rf_grid_search_test[:,1]]).transpose()\n",
    "X_occ_test_proba_df.columns = ['PredictedProbability']\n",
    "\n",
    "# split dataset to include survival time in X for c-index calculation\n",
    "X_occ_cindex = completed_occ_df.drop(axis=1, columns=['PatientID', 'TumourSite', 'TwoYearHNCDeath'])\n",
    "y_occ_cindex = completed_occ_df['TwoYearHNCDeath']\n",
    "# create balanced dataset with survival time\n",
    "smote = SMOTE(random_state=1, k_neighbors=5)\n",
    "X_occ_cindex_smote, y_occ_cindex_smote = smote.fit_resample(X_occ_cindex, y_occ_cindex)\n",
    "# split the dataset into X and y\n",
    "X_occ_train_cindex, X_occ_test_cindex, y_occ_train_cindex, y_occ_test_cindex = train_test_split(X_occ_cindex_smote, y_occ_cindex_smote, stratify=y_occ_cindex_smote, random_state=0, test_size = 0.2)\n",
    "\n",
    "# append predicted outcome and probability to test set using indexes\n",
    "occ_X_test_df = X_occ_test.copy()\n",
    "occ_X_test_df['SurvivalMonths'] = X_occ_test_cindex['SurvivalMonths']\n",
    "occ_X_test_df['TwoYearHNCDeath']= y_occ_test\n",
    "occ_X_test_df.reset_index(inplace=True)\n",
    "occ_X_test_df['PredictedOutcome'] = X_occ_test_pred_df\n",
    "occ_X_test_df['PredictedProbability'] = X_occ_test_proba_df\n",
    "# print(occ_X_test_df)\n",
    "\n",
    "# calculate c-index\n",
    "occ_cindex = concordance_index(occ_X_test_df['SurvivalMonths'], -occ_X_test_df['PredictedProbability'], occ_X_test_df['TwoYearHNCDeath']) # the negative value is used for probability, see documentation\n",
    "print(\"c-index=\", occ_cindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6955a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run 1000 sample bootstrap to calculate 95% CI for c-index\n",
    "occ_cindex_score = []\n",
    "n_iterations = 1000\n",
    "for i in range(n_iterations):\n",
    "    time, prob, event = resample(X_occ_test_cindex['SurvivalMonths'], X_occ_test_proba_df, y_occ_test, replace=True)\n",
    "    occ_ci_score = concordance_index(time, prob, event)\n",
    "    occ_cindex_score.append(occ_ci_score)\n",
    "\n",
    "# sns.kdeplot(occ_cindex_score)\n",
    "# plt.show()\n",
    "\n",
    "# calculate 95% CI of cindex\n",
    "occ_cindex_25_percentile = np.percentile(occ_cindex_score, 25)\n",
    "print('25th percentile occ:', 1-occ_cindex_25_percentile)\n",
    "occ_cindex_50_percentile = np.percentile(occ_cindex_score, 50) # value should be very close to calculated c-index score\n",
    "print('50th percentile occ:', 1-occ_cindex_50_percentile)\n",
    "occ_cindex_75_percentile = np.percentile(occ_cindex_score, 75)\n",
    "print('75th percentile occ:', 1-occ_cindex_75_percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9912ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "pickle.dump(occ_grid_search_rf, open('/PATH/TO/FILE.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc80ae17",
   "metadata": {},
   "source": [
    "# kaplan meier - occ dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fc9513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset with survival time included for merging to dataset with pred and proba without oversampling\n",
    "X_occ_surv = completed_occ_df.drop(axis=1, columns=['PatientID', 'TumourSite', 'TwoYearHNCDeath'])\n",
    "y_occ_surv = completed_occ_df['TwoYearHNCDeath']\n",
    "X_occ_surv_train_time, X_occ_surv_test_time, y_occ_surv_train, y_occ_surv_test = train_test_split(X_occ_surv, y_occ_surv, stratify=y_occ_surv, random_state=0, test_size = 0.2)\n",
    "# remove survival time from X train and test\n",
    "X_occ_surv_train = X_occ_surv_train_time.drop(axis=1, columns=['SurvivalMonths'])\n",
    "# print(X_occ_surv_train)\n",
    "X_occ_surv_test = X_occ_surv_test_time.drop(axis=1, columns=['SurvivalMonths'])\n",
    "# print(X_occ_surv_test)\n",
    "\n",
    "# use gridsearchCV to find for parameter tuning \n",
    "max_features = [\"sqrt\", \"log2\"]\n",
    "n_estimators = [100, 1000, 10000, 100000]\n",
    "class_weight = [{0:.1, 1:.9}, {0:.2, 1:0.8}, {0:.3, 1:.7}, {0:.4, 1:.6}, {0:.5, 1:.5}]\n",
    "\n",
    "# create parameter dictionary for tuning\n",
    "occ_surv_rf_param_grid = dict(max_features=max_features,\n",
    "                            n_estimators=n_estimators, \n",
    "                            class_weight=class_weight)\n",
    "\n",
    "# define the gridsearchCV object with 5 CV\n",
    "occ_surv_grid_search_rf = GridSearchCV(rf, param_grid=occ_surv_rf_param_grid, cv=5, n_jobs=-1, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69229b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the tree gridsearchCV object\n",
    "occ_surv_grid_search_rf.fit(X_occ_surv_train, y_occ_surv_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bafdd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best parameters and average accuracy score\n",
    "print(\"Best parameters: {}\".format(occ_surv_grid_search_rf.best_params_))\n",
    "print(\"Best cross-validation average accuracy score: {:.2f}\".format(occ_surv_grid_search_rf.best_score_))\n",
    "\n",
    "# predict outcome using tuned model on train set\n",
    "y_pred_occ_surv_rf_grid_search_train = occ_surv_grid_search_rf.predict(X_occ_surv_train)\n",
    "# predict probabilities on train set\n",
    "y_prob_occ_surv_rf_grid_search_train = occ_surv_grid_search_rf.predict_proba(X_occ_surv_train)\n",
    "# print(y_prob_occ_surv_rf_grid_search_train)\n",
    "\n",
    "# calculate percentiles on train set\n",
    "occ_surv_train_25_percentile = np.percentile (y_prob_occ_surv_rf_grid_search_train[:,1], 25) # for prediction of class 1 'death'\n",
    "# print('25th percentile:', occ_surv_train_25_percentile)\n",
    "occ_surv_train_50_percentile = np.percentile (y_prob_occ_surv_rf_grid_search_train[:,1], 50)\n",
    "# print('50th percentile:', occ_surv_train_50_percentile)\n",
    "occ_surv_train_75_percentile = np.percentile (y_prob_occ_surv_rf_grid_search_train[:,1], 75)\n",
    "# print('75th percentile:', occ_surv_train_75_percentile)\n",
    "\n",
    "# predict outcome using tuned model on test set\n",
    "y_pred_occ_surv_rf_grid_search_test = occ_surv_grid_search_rf.predict(X_occ_surv_test)\n",
    "# print(y_pred_occ_surv_rf_grid_search_test)\n",
    "# predict probabilities on test set\n",
    "y_prob_occ_surv_rf_grid_search_test = occ_surv_grid_search_rf.predict_proba(X_occ_surv_test)\n",
    "# print(y_prob_occ_surv_rf_grid_search_test[:,1])\n",
    "\n",
    "# calculate percentiles on test set\n",
    "X_occ_surv_test_25_percentile = np.percentile (y_prob_occ_surv_rf_grid_search_test[:,1], 25)\n",
    "# print('25th percentile:', X_occ_surv_test_25_percentile)\n",
    "X_occ_surv_test_50_percentile = np.percentile (y_prob_occ_surv_rf_grid_search_test[:,1], 50)\n",
    "# print('50th percentile:', X_occ_surv_test_50_percentile)\n",
    "X_occ_surv_test_75_percentile = np.percentile (y_prob_occ_surv_rf_grid_search_test[:,1], 75)\n",
    "# print('75th percentile:', X_occ_surv_test_75_percentile)\n",
    "\n",
    "# print the accuracy scores\n",
    "print(\"Accuracy on training set: {:.2f}\".format(accuracy_score(y_occ_surv_train, y_pred_occ_surv_rf_grid_search_train)))\n",
    "print(\"Accuracy on test set: {:.2f}\".format(accuracy_score(y_occ_surv_test, y_pred_occ_surv_rf_grid_search_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b2b984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance metrics of the tuned model, construct the confusion matrix\n",
    "cm_occ_surv_rf = confusion_matrix(y_true = y_occ_surv_test, y_pred = y_pred_occ_surv_rf_grid_search_test)\n",
    "# plot confusion matrix\n",
    "print(\"Confusion matrix plot of the rf:\")\n",
    "print(cm_occ_surv_rf)\n",
    "print()\n",
    "print(\"Confusion matrix plot of the rf:\")\n",
    "disease_labels = ['HNC death Absent', 'HNC death Present']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm_occ_surv_rf)\n",
    "plt.title('Confusion matrix of the rf:')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + disease_labels)\n",
    "ax.set_yticklabels([''] + disease_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe53666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print classification report\n",
    "print(\"Precision, Recall, F1-score for class 0 (HNC death Absent) and class 1 (HNC death Present) classes of the test set:\")\n",
    "print(\"Using random forest model\")\n",
    "print()\n",
    "print(classification_report(y_occ_surv_test, y_pred_occ_surv_rf_grid_search_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084e52ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create auc roc curve\n",
    "y_pred_proba_occ_surv_rf = occ_surv_grid_search_rf.predict_proba(X_occ_surv_test)[:,1]\n",
    "print(\"Area under curve for random forest:\")\n",
    "print(metrics.roc_auc_score(y_true = y_occ_surv_test, y_score = y_pred_occ_surv_rf_grid_search_test))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_occ_surv_test, y_pred_occ_surv_rf_grid_search_test)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='red', lw=2, label='ROC curve random forest')\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b7053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "pickle.dump(occ_surv_grid_search_rf, open('/PATH/TO/FILE.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6deafce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pred/proba arrays to dataframes and add column labels\n",
    "X_occ_surv_test_pred_df = pd.DataFrame([y_pred_occ_surv_rf_grid_search_test]).transpose()\n",
    "X_occ_surv_test_pred_df.columns = ['PredictedOutcome']\n",
    "X_occ_surv_test_proba_df = pd.DataFrame([y_prob_occ_surv_rf_grid_search_test[:,1]]).transpose()\n",
    "X_occ_surv_test_proba_df.columns = ['PredictedProbability']\n",
    "\n",
    "# append predicted outcome and probability to test set using indexes\n",
    "occ_km_df = X_occ_surv_test.copy()\n",
    "occ_km_df['SurvivalMonths'] = X_occ_surv_test_time['SurvivalMonths']\n",
    "occ_km_df['TwoYearHNCDeath']= y_occ_surv_test\n",
    "occ_km_df.reset_index(inplace=True)\n",
    "occ_km_df['PredictedOutcome'] = X_occ_surv_test_pred_df\n",
    "occ_km_df['PredictedProbability'] = X_occ_surv_test_proba_df\n",
    "# print(occ_km_df)\n",
    "\n",
    "# create risk group variable, 3=poor prognosis, 2=medium prognosis, 1=good prognosis\n",
    "occ_km_df['RiskGroup'] = [3 if x<occ_surv_train_25_percentile else 1 if x>occ_surv_train_75_percentile else 2 for x in occ_km_df['PredictedProbability']]\n",
    "# print(occ_km_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c457bd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot km curve for risk group\n",
    "fig, ax = plt.subplots(figsize=(6,6), dpi=80)\n",
    "df = occ_km_df\n",
    "ix = df['RiskGroup'] == 'riskgroup'\n",
    "\n",
    "occ_km_rg1 = KaplanMeierFitter()\n",
    "ax = occ_km_rg1.fit(df[df[\"RiskGroup\"] == 1]['SurvivalMonths'], df[df[\"RiskGroup\"] == 1]['TwoYearHNCDeath'], label='poor prognosis').plot_survival_function(ax=ax)\n",
    "\n",
    "occ_km_rg2 = KaplanMeierFitter()\n",
    "ax = occ_km_rg2.fit(df[df[\"RiskGroup\"] == 2]['SurvivalMonths'], df[df[\"RiskGroup\"] == 2]['TwoYearHNCDeath'], label='medium prognosis').plot_survival_function(ax=ax)\n",
    "\n",
    "occ_km_rg3 = KaplanMeierFitter()\n",
    "ax = occ_km_rg3.fit(df[df[\"RiskGroup\"] == 3]['SurvivalMonths'], df[df[\"RiskGroup\"] == 3]['TwoYearHNCDeath'], label='good prognosis').plot_survival_function(ax=ax)\n",
    "\n",
    "from lifelines.plotting import add_at_risk_counts\n",
    "add_at_risk_counts(occ_km_rg1, occ_km_rg2, occ_km_rg3, ax=ax)\n",
    "ax.set_xlabel(\"Survival time (months)\")\n",
    "ax.set_xlim(0, 24) # set x axis to 24 months\n",
    "ax.set_ylabel(\"Survival\")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[::-1], labels[::-1], loc='lower left')\n",
    "plt.tight_layout()\n",
    "\n",
    "# save km figure\n",
    "plt.savefig(\"/PATH/TO/FILE.jpeg\", dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4081c6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print event table for each risk group\n",
    "print(occ_km_rg1.event_table)\n",
    "print(occ_km_rg2.event_table)\n",
    "print(occ_km_rg3.event_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11e9902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate log rank statistics\n",
    "occ_results = multivariate_logrank_test(occ_km_df['SurvivalMonths'], occ_km_df['RiskGroup'], occ_km_df['TwoYearHNCDeath'])\n",
    "occ_results.print_summary()\n",
    "print(\"p value =\", occ_results.p_value)        \n",
    "print(\"t statistic =\", occ_results.test_statistic) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0c65ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate c-index\n",
    "occ_surv_cindex = concordance_index(occ_km_df['SurvivalMonths'], -occ_km_df['PredictedProbability'], occ_km_df['TwoYearHNCDeath'])\n",
    "print(occ_surv_cindex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f2a9f6",
   "metadata": {},
   "source": [
    "# prediction - opc dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1977c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate random forest model\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "# split into 80% train and 20% test using oversampled dataset\n",
    "X_opc_train, X_opc_test, y_opc_train, y_opc_test = train_test_split(X_opc_smote, y_opc_smote, stratify=y_opc_smote, random_state=0, test_size = 0.2)\n",
    "# use gridsearchCV for parameter tuning \n",
    "max_features = [\"sqrt\", \"log2\"]\n",
    "n_estimators = [1000, 10000, 100000]\n",
    "class_weight = [{0:.1, 1:.9}, {0:.2, 1:0.8}, {0:.3, 1:.7}, {0:.4, 1:.6}, {0:.5, 1:.5}]\n",
    "# create parameter dictionary for tuning\n",
    "opc_rf_param_grid = dict(max_features=max_features,\n",
    "                            n_estimators=n_estimators, \n",
    "                            class_weight=class_weight)\n",
    "# define the gridsearchCV object with 5 CV\n",
    "opc_grid_search_rf = GridSearchCV(rf, param_grid=opc_rf_param_grid, cv=5, n_jobs=-1, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1959912f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the tree gridsearchCV object\n",
    "opc_grid_search_rf.fit(X_opc_train, y_opc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4afad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best parameters and average accuracy score\n",
    "print(\"Best parameters: {}\".format(opc_grid_search_rf.best_params_))\n",
    "print(\"Best cross-validation average accuracy score: {:.2f}\".format(opc_grid_search_rf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3b3630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict outcome on train set\n",
    "y_pred_opc_rf_grid_search_train = opc_grid_search_rf.predict(X_opc_train)\n",
    "# predict probabilities on train set\n",
    "y_prob_opc_rf_grid_search_train = opc_grid_search_rf.predict_proba(X_opc_train)\n",
    "# predict outcome on test set\n",
    "y_pred_opc_rf_grid_search_test = opc_grid_search_rf.predict(X_opc_test)\n",
    "# predict probabilities on test set\n",
    "y_prob_opc_rf_grid_search_test = opc_grid_search_rf.predict_proba(X_opc_test)\n",
    "# print(y_prob_opc_rf_grid_search_test[:,1])\n",
    "\n",
    "# print the accuracy scores\n",
    "print(\"Accuracy on training set: {:.2f}\".format(accuracy_score(y_opc_train, y_pred_opc_rf_grid_search_train)))\n",
    "print(\"Accuracy on test set: {:.2f}\".format(accuracy_score(y_opc_test, y_pred_opc_rf_grid_search_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00eef100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance metrics of the tuned model, construct the confusion matrix\n",
    "cm_opc_rf = confusion_matrix(y_true = y_opc_test, y_pred = y_pred_opc_rf_grid_search_test)\n",
    "# plot confusion matrix\n",
    "print(\"Confusion matrix plot of the rf:\")\n",
    "print(cm_opc_rf)\n",
    "print()\n",
    "print(\"Confusion matrix plot of the rf:\")\n",
    "disease_labels = ['HNC death Absent', 'HNC death Present']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm_opc_rf)\n",
    "plt.title('Confusion matrix of the rf:')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + disease_labels)\n",
    "ax.set_yticklabels([''] + disease_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236cf05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print classification report\n",
    "print(\"Precision, Recall, F1-score for class 0 (HNC death Absent) and class 1 (HNC death Present) classes of the test set:\")\n",
    "print(\"Using random forest model\")\n",
    "print()\n",
    "print(classification_report(y_opc_test, y_pred_opc_rf_grid_search_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c04b6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create auc roc curve\n",
    "y_pred_proba_opc_rf = opc_grid_search_rf.predict_proba(X_opc_test)[:,1]\n",
    "print(\"Area under curve for random forest:\")\n",
    "print(metrics.roc_auc_score(y_true = y_opc_test, y_score = y_pred_proba_opc_rf))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_opc_test, y_pred_proba_opc_rf)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='red', lw=2, label='ROC curve random forest')\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e096983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate c-index\n",
    "# convert pred/proba arrays to dataframes and add column labels\n",
    "X_opc_test_pred_df = pd.DataFrame([y_pred_opc_rf_grid_search_test]).transpose()\n",
    "X_opc_test_pred_df.columns = ['PredictedOutcome']\n",
    "X_opc_test_proba_df = pd.DataFrame([y_prob_opc_rf_grid_search_test[:,1]]).transpose()\n",
    "X_opc_test_proba_df.columns = ['PredictedProbability']\n",
    "\n",
    "# split dataset to include survival time in X for c-index calculation\n",
    "X_opc_cindex = completed_opc_df.drop(axis=1, columns=['PatientID', 'TumourSite', 'TwoYearHNCDeath'])\n",
    "y_opc_cindex = completed_opc_df['TwoYearHNCDeath']\n",
    "# create balanced dataset with survival time\n",
    "smote = SMOTE(random_state=1, k_neighbors=5)\n",
    "X_opc_cindex_smote, y_opc_cindex_smote = smote.fit_resample(X_opc_cindex, y_opc_cindex)\n",
    "# split the dataset into X and y\n",
    "X_opc_train_cindex, X_opc_test_cindex, y_opc_train_cindex, y_opc_test_cindex = train_test_split(X_opc_cindex_smote, y_opc_cindex_smote, stratify=y_opc_cindex_smote, random_state=0, test_size = 0.2)\n",
    "\n",
    "# append predicted outcome and probability to test set using indexes\n",
    "opc_X_test_df = X_opc_test.copy()\n",
    "opc_X_test_df['SurvivalMonths'] = X_opc_test_cindex['SurvivalMonths']\n",
    "opc_X_test_df['TwoYearHNCDeath']= y_opc_test\n",
    "opc_X_test_df.reset_index(inplace=True)\n",
    "opc_X_test_df['PredictedOutcome'] = X_opc_test_pred_df\n",
    "opc_X_test_df['PredictedProbability'] = X_opc_test_proba_df\n",
    "# print(opc_X_test_df)\n",
    "\n",
    "# calculate c-index\n",
    "opc_cindex = concordance_index(opc_X_test_df['SurvivalMonths'], -opc_X_test_df['PredictedProbability'], opc_X_test_df['TwoYearHNCDeath']) # the negative value is used for probability, see documentation\n",
    "print(\"c-index=\", opc_cindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc57a66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run 1000 sample bootstrap to calculate 95% CI for c-index\n",
    "opc_cindex_score = []\n",
    "n_iterations = 1000\n",
    "for i in range(n_iterations):\n",
    "    time, prob, event = resample(X_opc_test_cindex['SurvivalMonths'], X_opc_test_proba_df, y_opc_test, replace=True)\n",
    "    opc_ci_score = concordance_index(time, prob, event)\n",
    "    opc_cindex_score.append(opc_ci_score)\n",
    "\n",
    "# sns.kdeplot(opc_cindex_score)\n",
    "# plt.show()\n",
    "\n",
    "# calculate 95% CI of cindex\n",
    "opc_cindex_25_percentile = np.percentile(opc_cindex_score, 25)\n",
    "print('25th percentile opc:', 1-opc_cindex_25_percentile)\n",
    "opc_cindex_50_percentile = np.percentile(opc_cindex_score, 50) # value should be very close to calculated c-index score\n",
    "print('50th percentile opc:', 1-opc_cindex_50_percentile)\n",
    "opc_cindex_75_percentile = np.percentile(opc_cindex_score, 75)\n",
    "print('75th percentile opc:', 1-opc_cindex_75_percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1aef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "pickle.dump(opc_grid_search_rf, open('/PATH/TO/FILE.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff79a6d",
   "metadata": {},
   "source": [
    "# kaplan meier - opc dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eebee41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset with survival time included for merging to dataset with pred and proba without oversampling\n",
    "X_opc_surv = completed_opc_df.drop(axis=1, columns=['PatientID', 'TumourSite', 'TwoYearHNCDeath'])\n",
    "y_opc_surv = completed_opc_df['TwoYearHNCDeath']\n",
    "X_opc_surv_train_time, X_opc_surv_test_time, y_opc_surv_train, y_opc_surv_test = train_test_split(X_opc_surv, y_opc_surv, stratify=y_opc_surv, random_state=0, test_size = 0.2)\n",
    "# remove survival time from X train and test\n",
    "X_opc_surv_train = X_opc_surv_train_time.drop(axis=1, columns=['SurvivalMonths'])\n",
    "# print(X_opc_surv_train)\n",
    "X_opc_surv_test = X_opc_surv_test_time.drop(axis=1, columns=['SurvivalMonths'])\n",
    "# print(X_opc_surv_test)\n",
    "\n",
    "# use gridsearchCV to find for parameter tuning \n",
    "max_features = [\"sqrt\", \"log2\"]\n",
    "n_estimators = [100, 1000, 10000, 100000]\n",
    "class_weight = [{0:.1, 1:.9}, {0:.2, 1:0.8}, {0:.3, 1:.7}, {0:.4, 1:.6}, {0:.5, 1:.5}]\n",
    "\n",
    "# create parameter dictionary for tuning\n",
    "opc_surv_rf_param_grid = dict(max_features=max_features,\n",
    "                            n_estimators=n_estimators, \n",
    "                            class_weight=class_weight)\n",
    "\n",
    "# define the gridsearchCV object with 5 CV\n",
    "opc_surv_grid_search_rf = GridSearchCV(rf, param_grid=opc_surv_rf_param_grid, cv=5, n_jobs=-1, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde5f63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the tree gridsearchCV object\n",
    "opc_surv_grid_search_rf.fit(X_opc_surv_train, y_opc_surv_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4c121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best parameters and average accuracy score\n",
    "print(\"Best parameters: {}\".format(opc_surv_grid_search_rf.best_params_))\n",
    "print(\"Best cross-validation average accuracy score: {:.2f}\".format(opc_surv_grid_search_rf.best_score_))\n",
    "\n",
    "# predict outcome using tuned model on train set\n",
    "y_pred_opc_surv_rf_grid_search_train = opc_surv_grid_search_rf.predict(X_opc_surv_train)\n",
    "# predict probabilities on train set\n",
    "y_prob_opc_surv_rf_grid_search_train = opc_surv_grid_search_rf.predict_proba(X_opc_surv_train)\n",
    "# print(y_prob_opc_surv_rf_grid_search_train)\n",
    "\n",
    "# calculate percentiles on train set\n",
    "opc_surv_train_25_percentile = np.percentile (y_prob_opc_surv_rf_grid_search_train[:,1], 25) # for prediction of class 1 'death'\n",
    "# print('25th percentile:', opc_surv_train_25_percentile)\n",
    "opc_surv_train_50_percentile = np.percentile (y_prob_opc_surv_rf_grid_search_train[:,1], 50)\n",
    "# print('50th percentile:', opc_surv_train_50_percentile)\n",
    "opc_surv_train_75_percentile = np.percentile (y_prob_opc_surv_rf_grid_search_train[:,1], 75)\n",
    "# print('75th percentile:', opc_surv_train_75_percentile)\n",
    "\n",
    "# predict outcome using tuned model on test set\n",
    "y_pred_opc_surv_rf_grid_search_test = opc_surv_grid_search_rf.predict(X_opc_surv_test)\n",
    "# print(y_pred_opc_surv_rf_grid_search_test)\n",
    "# predict probabilities on test set\n",
    "y_prob_opc_surv_rf_grid_search_test = opc_surv_grid_search_rf.predict_proba(X_opc_surv_test)\n",
    "# print(y_prob_opc_surv_rf_grid_search_test[:,1])\n",
    "\n",
    "# calculate percentiles on test set\n",
    "X_opc_surv_test_25_percentile = np.percentile (y_prob_opc_surv_rf_grid_search_test[:,1], 25)\n",
    "# print('25th percentile:', X_opc_surv_test_25_percentile)\n",
    "X_opc_surv_test_50_percentile = np.percentile (y_prob_opc_surv_rf_grid_search_test[:,1], 50)\n",
    "# print('50th percentile:', X_opc_surv_test_50_percentile)\n",
    "X_opc_surv_test_75_percentile = np.percentile (y_prob_opc_surv_rf_grid_search_test[:,1], 75)\n",
    "# print('75th percentile:', X_opc_surv_test_75_percentile)\n",
    "\n",
    "# print the accuracy scores\n",
    "print(\"Accuracy on training set: {:.2f}\".format(accuracy_score(y_opc_surv_train, y_pred_opc_surv_rf_grid_search_train)))\n",
    "print(\"Accuracy on test set: {:.2f}\".format(accuracy_score(y_opc_surv_test, y_pred_opc_surv_rf_grid_search_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4416db50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance metrics of the tuned model, construct the confusion matrix\n",
    "cm_opc_surv_rf = confusion_matrix(y_true = y_opc_surv_test, y_pred = y_pred_opc_surv_rf_grid_search_test)\n",
    "# plot confusion matrix\n",
    "print(\"Confusion matrix plot of the rf:\")\n",
    "print(cm_opc_surv_rf)\n",
    "print()\n",
    "print(\"Confusion matrix plot of the rf:\")\n",
    "disease_labels = ['HNC death Absent', 'HNC death Present']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm_opc_surv_rf)\n",
    "plt.title('Confusion matrix of the rf:')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + disease_labels)\n",
    "ax.set_yticklabels([''] + disease_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228d679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print classification report\n",
    "print(\"Precision, Recall, F1-score for class 0 (HNC death Absent) and class 1 (HNC death Present) classes of the test set:\")\n",
    "print(\"Using random forest model\")\n",
    "print()\n",
    "print(classification_report(y_opc_surv_test, y_pred_opc_surv_rf_grid_search_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6f671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create auc roc curve\n",
    "y_pred_proba_opc_surv_rf = opc_surv_grid_search_rf.predict_proba(X_opc_surv_test)[:,1]\n",
    "print(\"Area under curve for random forest:\")\n",
    "print(metrics.roc_auc_score(y_true = y_opc_surv_test, y_score = y_pred_opc_surv_rf_grid_search_test))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_opc_surv_test, y_pred_opc_surv_rf_grid_search_test)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='red', lw=2, label='ROC curve random forest')\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=2, linestyle='--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1b9204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "pickle.dump(opc_surv_grid_search_rf, open('/PATH/TO/FILE.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397403f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pred/proba arrays to dataframes and add column labels\n",
    "X_opc_surv_test_pred_df = pd.DataFrame([y_pred_opc_surv_rf_grid_search_test]).transpose()\n",
    "X_opc_surv_test_pred_df.columns = ['PredictedOutcome']\n",
    "X_opc_surv_test_proba_df = pd.DataFrame([y_prob_opc_surv_rf_grid_search_test[:,1]]).transpose()\n",
    "X_opc_surv_test_proba_df.columns = ['PredictedProbability']\n",
    "\n",
    "# append predicted outcome and probability to test set using indexes\n",
    "opc_km_df = X_opc_surv_test.copy()\n",
    "opc_km_df['SurvivalMonths'] = X_opc_surv_test_time['SurvivalMonths']\n",
    "opc_km_df['TwoYearHNCDeath']= y_opc_surv_test\n",
    "opc_km_df.reset_index(inplace=True)\n",
    "opc_km_df['PredictedOutcome'] = X_opc_surv_test_pred_df\n",
    "opc_km_df['PredictedProbability'] = X_opc_surv_test_proba_df\n",
    "# print(opc_km_df)\n",
    "\n",
    "# create risk group variable, 3=poor prognosis, 2=medium prognosis, 1=good prognosis\n",
    "opc_km_df['RiskGroup'] = [3 if x<opc_surv_train_25_percentile else 1 if x>opc_surv_train_75_percentile else 2 for x in opc_km_df['PredictedProbability']]\n",
    "# print(opc_km_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2f9cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot km curve for risk group\n",
    "fig, ax = plt.subplots(figsize=(6,6), dpi=80)\n",
    "\n",
    "df = opc_km_df\n",
    "ix = df['RiskGroup'] == 'riskgroup'\n",
    "\n",
    "opc_km_rg1 = KaplanMeierFitter()\n",
    "ax = opc_km_rg1.fit(df[df[\"RiskGroup\"] == 1]['SurvivalMonths'], df[df[\"RiskGroup\"] == 1]['TwoYearHNCDeath'], label='poor prognosis').plot_survival_function(ax=ax)\n",
    "\n",
    "opc_km_rg2 = KaplanMeierFitter()\n",
    "ax = opc_km_rg2.fit(df[df[\"RiskGroup\"] == 2]['SurvivalMonths'], df[df[\"RiskGroup\"] == 2]['TwoYearHNCDeath'], label='medium prognosis').plot_survival_function(ax=ax)\n",
    "\n",
    "opc_km_rg3 = KaplanMeierFitter()\n",
    "ax = opc_km_rg3.fit(df[df[\"RiskGroup\"] == 3]['SurvivalMonths'], df[df[\"RiskGroup\"] == 3]['TwoYearHNCDeath'], label='good prognosis').plot_survival_function(ax=ax)\n",
    "\n",
    "from lifelines.plotting import add_at_risk_counts\n",
    "add_at_risk_counts(opc_km_rg1, opc_km_rg2, opc_km_rg3, ax=ax)\n",
    "ax.set_xlabel(\"Survival time (months)\")\n",
    "ax.set_xlim(0, 24) # set x axis to 24 months\n",
    "ax.set_ylabel(\"Survival\")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[::-1], labels[::-1], loc='lower left')\n",
    "plt.tight_layout()\n",
    "\n",
    "# save km figure\n",
    "plt.savefig(\"/PATH/TO/FILE.jpeg\", dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be811e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print event table for each risk group\n",
    "print(opc_km_rg1.event_table)\n",
    "print(opc_km_rg2.event_table)\n",
    "print(opc_km_rg3.event_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18db2a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate log rank statistics\n",
    "opc_results = multivariate_logrank_test(opc_km_df['SurvivalMonths'], opc_km_df['RiskGroup'], opc_km_df['TwoYearHNCDeath'])\n",
    "opc_results.print_summary()\n",
    "print(\"p value =\", opc_results.p_value)        \n",
    "print(\"t statistic =\", opc_results.test_statistic) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b65def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate c-index\n",
    "opc_surv_cindex = concordance_index(opc_km_df['SurvivalMonths'], -opc_km_df['PredictedProbability'], opc_km_df['TwoYearHNCDeath'])\n",
    "print(opc_surv_cindex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a0b8b9",
   "metadata": {},
   "source": [
    "# calibration plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabe9077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate models\n",
    "# calibrated_hnc_model = CalibratedClassifierCV(hnc_grid_search_rf, method='sigmoid', cv=5)\n",
    "# calibrated_hpc_model = CalibratedClassifierCV(hpc_grid_search_rf, method='sigmoid', cv=5)\n",
    "# calibrated_lyx_model = CalibratedClassifierCV(lyx_grid_search_rf, method='sigmoid', cv=5)\n",
    "# calibrated_npc_model = CalibratedClassifierCV(npc_grid_search_rf, method='sigmoid', cv=5)\n",
    "# calibrated_occ_model = CalibratedClassifierCV(occ_grid_search_rf, method='sigmoid', cv=5)\n",
    "# calibrated_opc_model = CalibratedClassifierCV(opc_grid_search_rf, method='sigmoid', cv=5)\n",
    "\n",
    "# fit calibrated models\n",
    "# calibrated_hnc_model.fit(X_hnc_train, y_hnc_train)\n",
    "# calibrated_hpc_model.fit(X_hpc_train, y_hpc_train)\n",
    "# calibrated_lyx_model.fit(X_lyx_train, y_lyx_train)\n",
    "# calibrated_npc_model.fit(X_npc_train, y_npc_train)\n",
    "# calibrated_occ_model.fit(X_occ_train, y_occ_train)\n",
    "# calibrated_opc_model.fit(X_opc_train, y_opc_train)\n",
    "\n",
    "# predict probabilities\n",
    "hnc_probs = hnc_grid_search_rf.predict_proba(X_hnc_test)[:, 1]\n",
    "hpc_probs = hpc_grid_search_rf.predict_proba(X_hpc_test)[:, 1]\n",
    "lyx_probs = lyx_grid_search_rf.predict_proba(X_lyx_test)[:, 1]\n",
    "npc_probs = npc_grid_search_rf.predict_proba(X_npc_test)[:, 1]\n",
    "occ_probs = occ_grid_search_rf.predict_proba(X_occ_test)[:, 1]\n",
    "opc_probs = opc_grid_search_rf.predict_proba(X_opc_test)[:, 1]\n",
    "\n",
    "# reliability diagram\n",
    "fop_hnc, mpv_hnc = calibration_curve(y_hnc_test, hnc_probs, n_bins=10, normalize=True)\n",
    "fop_hpc, mpv_hpc = calibration_curve(y_hpc_test, hpc_probs, n_bins=10, normalize=True)\n",
    "fop_lyx, mpv_lyx = calibration_curve(y_lyx_test, lyx_probs, n_bins=10, normalize=True)\n",
    "fop_npc, mpv_npc = calibration_curve(y_npc_test, npc_probs, n_bins=10, normalize=True)\n",
    "fop_occ, mpv_occ = calibration_curve(y_occ_test, occ_probs, n_bins=10, normalize=True)\n",
    "fop_opc, mpv_opc = calibration_curve(y_opc_test, opc_probs, n_bins=10, normalize=True)\n",
    "\n",
    "# plot perfectly calibrated\n",
    "fig, ax = plt.subplots(figsize=(8,6), dpi=80)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='perfectly calibrated')\n",
    "\n",
    "# plot calibrated reliability\n",
    "plt.plot(mpv_hnc, fop_hnc, marker='.', label='head and neck')\n",
    "plt.plot(mpv_hpc, fop_hpc, marker='.', label='hypopharynx')\n",
    "plt.plot(mpv_lyx, fop_lyx, marker='.', label='larynx')\n",
    "plt.plot(mpv_npc, fop_npc, marker='.', label='nasopharynx')\n",
    "plt.plot(mpv_occ, fop_occ, marker='.', label='oralcavity')\n",
    "plt.plot(mpv_opc, fop_opc, marker='.', label='oropharynx')\n",
    "\n",
    "ax.set_xlabel('Predicted probability')\n",
    "ax.set_ylabel('Observed probability')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# save figure\n",
    "fig.savefig(\"/FILE/TO/PATH.jpeg\", dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c482162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print probabilities\n",
    "hnc_prob_y = y_hnc_test, y_pred_proba_hnc_rf\n",
    "print('hnc prob:', hnc_prob_y)\n",
    "hpc_prob_y = y_hpc_test, y_pred_proba_hpc_rf\n",
    "print('hpc prob:', hpc_prob_y)\n",
    "lyx_prob_y = y_lyx_test, y_pred_proba_lyx_rf\n",
    "print('lyx prob:', lyx_prob_y)\n",
    "npc_prob_y = y_npc_test, y_pred_proba_npc_rf\n",
    "print('npc prob:', npc_prob_y)\n",
    "occ_prob_y = y_occ_test, y_pred_proba_occ_rf\n",
    "print('occ prob:', occ_prob_y)\n",
    "opc_prob_y = y_opc_test, y_pred_proba_opc_rf\n",
    "print('opc prob:', opc_prob_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c29b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Brier score\n",
    "# brier_score_loss(y_true, y_prob)\n",
    "hnc_brier = brier_score_loss(y_hnc_test, y_pred_proba_hnc_rf)\n",
    "print('hnc brier:', hnc_brier)\n",
    "hpc_brier = brier_score_loss(y_hpc_test, y_pred_proba_hpc_rf)\n",
    "print('hpc brier:', hpc_brier)\n",
    "lyx_brier = brier_score_loss(y_lyx_test, y_pred_proba_lyx_rf)\n",
    "print('lyx brier:', lyx_brier)\n",
    "npc_brier = brier_score_loss(y_npc_test, y_pred_proba_npc_rf)\n",
    "print('npc brier:', npc_brier)\n",
    "occ_brier = brier_score_loss(y_occ_test, y_pred_proba_occ_rf)\n",
    "print('occ brier:', occ_brier)\n",
    "opc_brier = brier_score_loss(y_opc_test, y_pred_proba_opc_rf)\n",
    "print('opc brier:', opc_brier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63faa26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run 1000 sample bootstrap to calculate 95% CI for Brier score\n",
    "hnc_brier_score = []\n",
    "n_iterations = 1000\n",
    "for i in range(n_iterations):\n",
    "    hnc_bs_y_true, hnc_bs_y_pred = resample(y_hnc_test, y_pred_proba_hnc_rf, replace=True)\n",
    "    hnc_score = brier_score_loss(hnc_bs_y_true, hnc_bs_y_pred)\n",
    "    hnc_brier_score.append(hnc_score)\n",
    "\n",
    "# sns.kdeplot(hnc_brier_score)\n",
    "# plt.show()\n",
    "\n",
    "# calculate 95% CI of Brier score\n",
    "hnc_brier_25_percentile = np.percentile(hnc_brier_score, 25)\n",
    "print('25th percentile hnc:', hnc_brier_25_percentile)\n",
    "hnc_brier_50_percentile = np.percentile(hnc_brier_score, 50) # value should be very close to calculated Brier score\n",
    "print('50th percentile hnc:', hnc_brier_50_percentile)\n",
    "hnc_brier_75_percentile = np.percentile(hnc_brier_score, 75)\n",
    "print('75th percentile hnc:', hnc_brier_75_percentile)\n",
    "\n",
    "hpc_brier_score = []\n",
    "n_iterations = 1000\n",
    "for i in range(n_iterations):\n",
    "    hpc_bs_y_true, hpc_bs_y_pred = resample(y_hpc_test, y_pred_proba_hpc_rf, replace=True)\n",
    "    hpc_score = brier_score_loss(hpc_bs_y_true, hpc_bs_y_pred)\n",
    "    hpc_brier_score.append(hpc_score)\n",
    "\n",
    "# sns.kdeplot(hpc_brier_score)\n",
    "# plt.show()\n",
    "\n",
    "# calculate 95% CI of Brier score\n",
    "hpc_brier_25_percentile = np.percentile(hpc_brier_score, 25)\n",
    "print('25th percentile hpc:', hpc_brier_25_percentile)\n",
    "hpc_brier_50_percentile = np.percentile(hpc_brier_score, 50) # value should be very close to calculated Brier score\n",
    "print('50th percentile hpc:', hpc_brier_50_percentile)\n",
    "hpc_brier_75_percentile = np.percentile(hpc_brier_score, 75)\n",
    "print('75th percentile hpc:', hpc_brier_75_percentile)\n",
    "\n",
    "lyx_brier_score = []\n",
    "n_iterations = 1000\n",
    "for i in range(n_iterations):\n",
    "    lyx_bs_y_true, lyx_bs_y_pred = resample(y_lyx_test, y_pred_proba_lyx_rf, replace=True)\n",
    "    lyx_score = brier_score_loss(lyx_bs_y_true, lyx_bs_y_pred)\n",
    "    lyx_brier_score.append(lyx_score)\n",
    "\n",
    "# sns.kdeplot(lyx_brier_score)\n",
    "# plt.show()\n",
    "\n",
    "# calculate 95% CI of Brier score\n",
    "lyx_brier_25_percentile = np.percentile(lyx_brier_score, 25)\n",
    "print('25th percentile lyx:', lyx_brier_25_percentile)\n",
    "lyx_brier_50_percentile = np.percentile(lyx_brier_score, 50) # value should be very close to calculated Brier score\n",
    "print('50th percentile lyx:', lyx_brier_50_percentile)\n",
    "lyx_brier_75_percentile = np.percentile(lyx_brier_score, 75)\n",
    "print('75th percentile lyx:', lyx_brier_75_percentile)\n",
    "\n",
    "npc_brier_score = []\n",
    "n_iterations = 1000\n",
    "for i in range(n_iterations):\n",
    "    npc_bs_y_true, npc_bs_y_pred = resample(y_npc_test, y_pred_proba_npc_rf, replace=True)\n",
    "    npc_score = brier_score_loss(npc_bs_y_true, npc_bs_y_pred)\n",
    "    npc_brier_score.append(npc_score)\n",
    "\n",
    "# sns.kdeplot(npc_brier_score)\n",
    "# plt.show()\n",
    "\n",
    "# calculate 95% CI of Brier score\n",
    "npc_brier_25_percentile = np.percentile(npc_brier_score, 25)\n",
    "print('25th percentile npc:', npc_brier_25_percentile)\n",
    "npc_brier_50_percentile = np.percentile(npc_brier_score, 50) # value should be very close to calculated Brier score\n",
    "print('50th percentile npc:', npc_brier_50_percentile)\n",
    "npc_brier_75_percentile = np.percentile(npc_brier_score, 75)\n",
    "print('75th percentile npc:', npc_brier_75_percentile)\n",
    "\n",
    "occ_brier_score = []\n",
    "n_iterations = 1000\n",
    "for i in range(n_iterations):\n",
    "    occ_bs_y_true, occ_bs_y_pred = resample(y_occ_test, y_pred_proba_occ_rf, replace=True)\n",
    "    occ_score = brier_score_loss(occ_bs_y_true, occ_bs_y_pred)\n",
    "    occ_brier_score.append(occ_score)\n",
    "\n",
    "# sns.kdeplot(occ_brier_score)\n",
    "# plt.show()\n",
    "\n",
    "# calculate 95% CI of Brier score\n",
    "occ_brier_25_percentile = np.percentile(occ_brier_score, 25)\n",
    "print('25th percentile occ:', occ_brier_25_percentile)\n",
    "occ_brier_50_percentile = np.percentile(occ_brier_score, 50) # value should be very close to calculated Brier score\n",
    "print('50th percentile occ:', occ_brier_50_percentile)\n",
    "occ_brier_75_percentile = np.percentile(occ_brier_score, 75)\n",
    "print('75th percentile occ:', occ_brier_75_percentile)\n",
    "\n",
    "opc_brier_score = []\n",
    "n_iterations = 1000\n",
    "for i in range(n_iterations):\n",
    "    opc_bs_y_true, opc_bs_y_pred = resample(y_opc_test, y_pred_proba_opc_rf, replace=True)\n",
    "    opc_score = brier_score_loss(opc_bs_y_true, opc_bs_y_pred)\n",
    "    opc_brier_score.append(opc_score)\n",
    "\n",
    "# sns.kdeplot(opc_brier_score)\n",
    "# plt.show()\n",
    "\n",
    "# calculate 95% CI of Brier score\n",
    "opc_brier_25_percentile = np.percentile(opc_brier_score, 25)\n",
    "print('25th percentile opc:', opc_brier_25_percentile)\n",
    "opc_brier_50_percentile = np.percentile(opc_brier_score, 50) # value should be very close to calculated Brier score\n",
    "print('50th percentile opc:', opc_brier_50_percentile)\n",
    "opc_brier_75_percentile = np.percentile(opc_brier_score, 75)\n",
    "print('75th percentile opc:', opc_brier_75_percentile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c2a412",
   "metadata": {},
   "source": [
    "# feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8efc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print feature importance array\n",
    "print(\"Feature importances:\\n{}\".format(hnc_grid_search_rf.best_estimator_.feature_importances_))\n",
    "print(\"Feature importances:\\n{}\".format(hpc_grid_search_rf.best_estimator_.feature_importances_))\n",
    "print(\"Feature importances:\\n{}\".format(lyx_grid_search_rf.best_estimator_.feature_importances_))\n",
    "print(\"Feature importances:\\n{}\".format(npc_grid_search_rf.best_estimator_.feature_importances_))\n",
    "print(\"Feature importances:\\n{}\".format(occ_grid_search_rf.best_estimator_.feature_importances_))\n",
    "print(\"Feature importances:\\n{}\".format(opc_grid_search_rf.best_estimator_.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e302e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert array to dataframe and sort feature importance\n",
    "hnc_df_feature_importance = pd.DataFrame(hnc_grid_search_rf.best_estimator_.feature_importances_, index=X_hnc_smote.columns, columns=['feature importance']).sort_values('feature importance', ascending=True)\n",
    "hpc_df_feature_importance = pd.DataFrame(hpc_grid_search_rf.best_estimator_.feature_importances_, index=X_hpc_smote.columns, columns=['feature importance']).sort_values('feature importance', ascending=True)\n",
    "lyx_df_feature_importance = pd.DataFrame(lyx_grid_search_rf.best_estimator_.feature_importances_, index=X_lyx_smote.columns, columns=['feature importance']).sort_values('feature importance', ascending=True)\n",
    "npc_df_feature_importance = pd.DataFrame(npc_grid_search_rf.best_estimator_.feature_importances_, index=X_npc_smote.columns, columns=['feature importance']).sort_values('feature importance', ascending=True)\n",
    "occ_df_feature_importance = pd.DataFrame(occ_grid_search_rf.best_estimator_.feature_importances_, index=X_occ_smote.columns, columns=['feature importance']).sort_values('feature importance', ascending=True)\n",
    "opc_df_feature_importance = pd.DataFrame(opc_grid_search_rf.best_estimator_.feature_importances_, index=X_opc_smote.columns, columns=['feature importance']).sort_values('feature importance', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b2848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print sorted feature importance\n",
    "print(\"hnc feature importance:\", hnc_df_feature_importance)\n",
    "print(\"hpc feature importance:\", hpc_df_feature_importance)\n",
    "print(\"lyx feature importance:\", lyx_df_feature_importance)\n",
    "print(\"npc feature importance:\", npc_df_feature_importance)\n",
    "print(\"occ feature importance:\", occ_df_feature_importance)\n",
    "print(\"opc feature importance:\", opc_df_feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1eaefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate feature importance\n",
    "hnc = hnc_grid_search_rf.best_estimator_.feature_importances_\n",
    "hpc = hpc_grid_search_rf.best_estimator_.feature_importances_\n",
    "lyx = lyx_grid_search_rf.best_estimator_.feature_importances_\n",
    "npc = npc_grid_search_rf.best_estimator_.feature_importances_\n",
    "occ = occ_grid_search_rf.best_estimator_.feature_importances_\n",
    "opc = opc_grid_search_rf.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802939fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns to plot for hnc site\n",
    "index_hnc = ['EQD2T', 'N classification', 'T classification', 'Tumour site', 'Hospital location', 'Gender','Age']\n",
    "hnc_fi_df = pd.DataFrame({'head and neck': hnc\n",
    "                         }, \n",
    "                   index=index_hnc)\n",
    "# plot feature importances\n",
    "ax = hnc_fi_df.plot.barh(width=0.9)\n",
    "# save figure\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/PATH/TO/FILE.jpeg\", dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12c5a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_subsite = ['EQD2T', 'N classification', 'T classification', 'Hospital location', 'Gender','Age']\n",
    "subsite_fi_df = pd.DataFrame({'oropharynx': opc,\n",
    "                              'oral cavity': occ,\n",
    "                              'nasopharynx': npc,\n",
    "                              'larynx': lyx,                         \n",
    "                              'hypopharynx': hpc\n",
    "                             }, \n",
    "                   index=index_subsite)\n",
    "\n",
    "ax = subsite_fi_df.plot(kind='barh', width=0.9)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[::-1], labels[::-1], fontsize=8.5, loc='best', bbox_to_anchor=(0.5, 0.4, 0.5, 0.5))\n",
    "# save figure\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/PATH/TO/FILE.jpeg\", dpi=1200)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
